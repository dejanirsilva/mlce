<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Dejanir Silva">
  <title>Machine Learning for Computational Economics</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-cfda842e1c2da8cd79357d57ebaa6bca.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Machine Learning for Computational Economics</h1>
  <p class="subtitle"><span class="module-name">Module 05: The Deep Policy Iteration Method</span><br><span class="school-name">EDHEC Business School</span></p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dejanir Silva 
</div>
        <p class="quarto-title-affiliation">
            Purdue University
          </p>
    </div>
</div>

  <p class="date">January 2026</p>
</section>
<section id="introduction" class="slide level2 compact-slide">
<h2>Introduction</h2>
<p>In this module, we use machine-learning tools to solve high-dimensional problems in continuous time.</p>
<ul>
<li>We introduce the <span class="text-orange"><strong>Deep Policy Iteration (DPI)</strong></span> method, proposed by <span class="citation" data-cites="DuarteDuarteSilva2024">Duarte, Duarte, and Silva (<a href="#/references" role="doc-biblioref" onclick="">2024</a>)</span>.</li>
<li>It combines stochastic optimization, automatic differentiation, and neural-network function approximation.</li>
</ul>
<div style="margin-top: 1.5em;">

</div>
<p>We proceed in two steps.</p>
<ol type="1">
<li>We show how to overcome the three curses of dimensionality.</li>
<li>We describe a range of applications of the DPI method in <em>asset pricing</em>, <em>corporate finance</em>, and <em>portfolio choice</em>.</li>
</ol>
<div style="margin-top: 1.5em;">

</div>
<p>The module is organized as follows:</p>
<ol type="1">
<li>The Hyper-Dual Approach to Itô’s lemma</li>
<li>The DPI Method</li>
<li>Applications</li>
</ol>
</section>
<section>
<section id="i.-dealing-with-the-three-curses" class="title-slide slide level1 center">
<h1>I. Dealing with the Three Curses</h1>

</section>
<section id="the-dynamic-programming-problem" class="slide level2 compact-slide">
<h2>The Dynamic Programming Problem</h2>
<p>Consider a continuous-time optimal control problem in which an infinitely lived agent faces a <em>Markovian decision process (MDP)</em>.</p>
<ul>
<li>The system’s state is represented by a vector <span class="math inline">\(\mathbf{s}_t \in \mathbb{R}^n\)</span></li>
<li>The control is a vector <span class="math inline">\(\mathbf{c}_t \in \Gamma(\mathbf{s}_t) \subset \mathbb{R}^p\)</span>.</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>The agent’s objective is to maximize the expected discounted value of the reward function <span class="math inline">\(u(\mathbf{c}_t)\)</span>: <span class="math display">\[
V(\mathbf{s}) = \max_{\{\mathbf{c}_t\}_{t=0}^\infty} \mathbb{E}\left[ \left. \int_{0}^\infty e^{-\rho t} u(\mathbf{c}_t) dt  \right| \mathbf{s}_0 = \mathbf{s} \right],
\]</span> subject to the stochastic law of motion <span class="math display">\[
d\mathbf{s}_t = \mathbf{f}(\mathbf{s}_t, \mathbf{c}_t) dt + \mathbf{g}(\mathbf{s}_t, \mathbf{c}_t) d\mathbf{B}_t.
\]</span> where <span class="math inline">\(\mathbf{B}_t\)</span> is an <span class="math inline">\(m \times 1\)</span> vector of Brownian motions, <span class="math inline">\(\mathbf{f}(\mathbf{s}_t, \mathbf{c}_t) \in \mathbb{R}^n\)</span> is the drift, and <span class="math inline">\(\mathbf{g}(\mathbf{s}_t, \mathbf{c}_t) \in \mathbb{R}^{n\times m}\)</span> is the diffusion matrix.</p>
</div>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<div title="The HJB Equation.">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>The HJB Equation.</strong></p>
</div>
<div class="callout-content">
<p>The value function <span class="math inline">\(V(\mathbf{s})\)</span> satisfies the Hamilton–Jacobi–Bellman (HJB) equation: <span class="math display">\[
0 = \max_{\mathbf{c}\in\Gamma(\mathbf{s})} u(\mathbf{c}) - \rho V(\mathbf{s}) + \nabla_{\mathbf{s}} V(\mathbf{s}) \cdot \mathbf{f}(\mathbf{s},\mathbf{c}) + \tfrac{1}{2} \operatorname{Tr}(\mathbf{g}(\mathbf{s},\mathbf{c}) \mathbf{H}_{\mathbf{s}} V(\mathbf{s}) \mathbf{g}(\mathbf{s},\mathbf{c})),
\]</span> where <span class="math inline">\(\nabla_{\mathbf{s}} V(\mathbf{s})\)</span> and <span class="math inline">\(\mathbf{H}_{\mathbf{s}} V(\mathbf{s})\)</span> denote, respectively, the gradient and Hessian of the value function.</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="dealing-with-the-three-curses" class="slide level2 compact-slide">
<h2>Dealing with the Three Curses</h2>
<p>As discussed in Module 1, dynamic programming methods face three intertwined computational obstacles:</p>
<div class="columns">
<div class="column" style="width:33%;">
<div style="background-color: #0072b2; height: 4px; width: 100%; margin-bottom: 0.5em;">

</div>
<p><span class="text-blue"><strong>1<sup>st</sup> curse</strong></span></p>
<div style="margin-top: 0.4em; font-size: 0.9em;">
<p>Representing <span class="math inline">\(V(\mathbf{s})\)</span></p>
</div>
</div><div class="column" style="width:34%;">
<div style="background-color: #d55e00; height: 4px; width: 100%; margin-bottom: 0.5em;">

</div>
<p><span class="text-orange"><strong>2<sup>nd</sup> curse</strong></span></p>
<div style="margin-top: 0.4em; font-size: 0.9em;">
<p>Solving for <span class="math inline">\(\mathbf{c}\)</span> given <span class="math inline">\(V(\mathbf{s})\)</span></p>
</div>
</div><div class="column" style="width:33%;">
<div style="background-color: #009e73; height: 4px; width: 100%; margin-bottom: 0.5em;">

</div>
<p><span class="text-green"><strong>3<sup>rd</sup> curse</strong></span></p>
<div style="margin-top: 0.4em; font-size: 0.9em;">
<p>Computing <span class="math inline">\(\mathbb{E}[V(\mathbf{s}')]\)</span></p>
</div>
</div></div>
<div style="margin-top: 1.5em;">

</div>
<p>In this module, we present an algorithm that addresses each of these curses using modern machine-learning tools:</p>
<ol type="1">
<li><strong>Neural networks</strong> provide compact representations of value and policy functions, circumventing the <em>curse of representation</em>;</li>
<li><strong>Stochastic optimization</strong> replace costly root-finding procedures, alleviating the <em>curse of optimization</em>;</li>
<li><strong>Automatic differentiation</strong> enables efficient computation of drift terms needed for the HJB, mitigating the <em>curse of expectation</em>;</li>
</ol>
</section></section>
<section>
<section id="ii.-overcoming-the-curse-of-expectation" class="title-slide slide level1 compact-slide center">
<h1>II. Overcoming the Curse of Expectation</h1>

</section>
<section id="from-integration-to-differentiation" class="slide level2 compact-slide">
<h2>From integration to differentiation</h2>
<p>In discrete time, the Bellman equation involves the expectation of the continuation value: <span class="math display">\[
\mathbb{E}[V(\mathbf{s}')] = \int \!\!\cdots\!\! \int V(\mathbf{s} + \mathbf{f}(\mathbf{s},\mathbf{c}) \Delta t + \mathbf{g}(\mathbf{s},\mathbf{c}) \sqrt{\Delta t} \mathbf{Z}) \phi(\mathbf{Z}) d\mathbf{Z}_1 \cdots d\mathbf{Z}_m,
\]</span> where <span class="math inline">\(\phi(\mathbf{Z})\)</span> is the joint density of the shocks.</p>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>In continuous time, the expected change in the value function can be written as <span class="math display">\[
\mathbb{E}[d V(\mathbf{s})] = \nabla_{\mathbf{s}} V(\mathbf{s}) \cdot \mathbf{f}(\mathbf{s},\mathbf{c}) + \tfrac{1}{2} \operatorname{Tr}(\mathbf{g}(\mathbf{s},\mathbf{c}) \mathbf{H}_{\mathbf{s}} V(\mathbf{s}) \mathbf{g}(\mathbf{s},\mathbf{c})),
\]</span></p>
<p>Hence, instead of computing high-dimensional integrals, we only need to compute derivatives of the value function.</p>
</div>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<div title="Computational challenge.">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Computational challenge.</strong></p>
</div>
<div class="callout-content">
<p>One could use finite differences to compute these derivatives</p>
<ul>
<li>But storing the solution on a grid becomes infeasible in higher dimensions.</li>
</ul>
<p>Suppose <span class="math inline">\(n=10\)</span> and we use a grid of 100 points for each state variable.</p>
<ul>
<li>Then, just to store the grid in memory, we would need <span class="math inline">\(10^{17}\)</span> terabytes of RAM.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="comparing-the-computational-costs" class="slide level2 compact-slide">
<h2>Comparing the Computational Costs</h2>
<p>To illustrate the computational challenge, we study a simple example.</p>
<div style="border-top: 1px solid #ccc; margin: 0.5em 0;">

</div>
<div class="columns">
<div class="column" style="width:50%;">
<p>Consider the following function: <span class="math display">\[
V(\mathbf{s}) = \sum_{i=1}^n s_i^2,
\]</span> where <span class="math inline">\(\mathbf{s} = (s_1, \ldots, s_n)\)</span> is a vector of state variables.</p>
</div><div class="column" style="width:50%;">
<p>A high-dimensional problem with <span class="math inline">\(n=100\)</span> state variables</p>
<ul>
<li>We evaluate the drift at the point <span class="math inline">\(\mathbf{s} = \mathbf{1}_{n\times1}\)</span>.</li>
<li>We focus on the case of a single shock (<span class="math inline">\(m=1\)</span>).</li>
</ul>
</div></div>
<div style="border-top: 1px solid #ccc; margin: 0.5em 0;">

</div>
<div class="fragment">
<p>We consider initially the following methods to compute the drift <span class="math inline">\(\mathbb{E}[d V(\mathbf{s})]\)</span>:</p>
<ol type="1">
<li><span class="text-blue"><strong>Finite differences</strong></span></li>
<li><span class="text-orange"><strong>Naive autodiff</strong></span></li>
</ol>
<div title="Comparing the Computational Costs.">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Comparing the Computational Costs.</strong></p>
</div>
<div class="callout-content">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: right;">FLOPs</th>
<th style="text-align: right;">Memory</th>
<th style="text-align: right;">Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1. Finite differences</td>
<td style="text-align: right;">9,190,800</td>
<td style="text-align: right;">112,442,048</td>
<td style="text-align: right;">1.58%</td>
</tr>
<tr class="even">
<td style="text-align: left;">2. Naive autodiff</td>
<td style="text-align: right;">2,100,501</td>
<td style="text-align: right;">25,673,640</td>
<td style="text-align: right;">0.00%</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<p>Even the naive autodiff method is computationally costly and memory intensive.</p>
<ul>
<li>The naive method computes the Hessian by nested calls to the Jacobian function</li>
</ul>
</div>
</section>
<section id="overcoming-the-curse-of-expectation" class="slide level2 compact-slide">
<h2>Overcoming the Curse of Expectation</h2>
<p>One of the key insights from Module 4 is that the <span class="text-orange"><strong>Jacobian–vector product</strong></span> (JVP) can be efficiently computed.</p>
<ul>
<li>Much less expensive than forming the full Jacobian.</li>
</ul>
<div style="margin-top: 1.5em;">

</div>
<div class="fragment">
<p>In the absence of shocks, computing the drift of <span class="math inline">\(V(\mathbf{s})\)</span> amounts to evaluating a JVP:</p>
<p><span class="math display">\[
\mathbb{E}[d V(\mathbf{s})] = \nabla_{\mathbf{s}} V(\mathbf{s})^\top \mathbf{f}(\mathbf{s},\mathbf{c}) dt,
\]</span> which can be efficiently computed using forward-mode AD.</p>
<div style="margin-top: 1.5em;">

</div>
<p>In the presence of shocks, the drift also depends on quadratic forms involving the Hessian of <span class="math inline">\(V(\mathbf{s})\)</span>.</p>
<ul>
<li>In this case, a JVP is no longer sufficient.</li>
</ul>
</div>
<div class="fragment">
<p>The <span class="text-blue"><strong>Hyper-dual approach</strong></span> to Itô’s lemma extends the idea of dual numbers to compute the drift of <span class="math inline">\(V(\mathbf{s})\)</span>.</p>
<ul>
<li>Regular dual numbers only store the function value and its derivative.</li>
<li>Hyper-dual numbers store the function value, its drift, and its diffusion matrix.</li>
</ul>
</div>
</section>
<section id="the-hyper-dual-approach-to-itôs-lemma" class="slide level2 compact-slide">
<h2>The Hyper-Dual Approach to Itô’s lemma</h2>
<p>The next result formalizes the hyper-dual approach to Itô’s lemma.</p>
<ul>
<li>It reduces the problem of computing the drift of <span class="math inline">\(V(\mathbf{s})\)</span> to evaluating the second derivative of a <em>univariate auxiliary function</em>.</li>
</ul>
<div title="Hyper-dual Itô's lemma">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Hyper-dual Itô’s lemma</strong></p>
</div>
<div class="callout-content">
<p>For a given <span class="math inline">\(\mathbf{s}\)</span>, define the auxiliary functions <span class="math inline">\(F_i:\mathbb{R}\rightarrow\mathbb{R}\)</span> as <span class="math display">\[
F_i(\epsilon;\mathbf{s}) = V\!\left(\mathbf{s} + \tfrac{\mathbf{g}_i(\mathbf{s})}{\sqrt{2}}\,\epsilon + \tfrac{\mathbf{f}(\mathbf{s})}{2m}\,\epsilon^2 \right),
\]</span> where <span class="math inline">\(\mathbf{f}(\mathbf{s})\)</span> is the drift of <span class="math inline">\(\mathbf{s}\)</span> and <span class="math inline">\(\mathbf{g}_i(\mathbf{s})\)</span> is the <span class="math inline">\(i\)</span>-th column of the diffusion matrix <span class="math inline">\(\mathbf{g}(\mathbf{s})\)</span>.</p>
<p>Then:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Diffusion:</strong> The <span class="math inline">\(1\times m\)</span> diffusion matrix of <span class="math inline">\(V(\mathbf{s})\)</span> is <span class="math display">\[
\nabla V(\mathbf{s})^{\top}\mathbf{g}(\mathbf{s}) = \sqrt{2}\,[F_1'(0;\mathbf{s}), F_2'(0;\mathbf{s}), \ldots, F_m'(0;\mathbf{s})].
\]</span></p>
</div><div class="column" style="width:50%;">
<p><strong>Drift:</strong> The drift of <span class="math inline">\(V(\mathbf{s})\)</span> is <span class="math display">\[
\mathcal{D}V(\mathbf{s}) = F''(0;\mathbf{s}), \qquad \text{where} \quad F(\epsilon;\mathbf{s}) = \sum_{i=1}^m F_i(\epsilon;\mathbf{s})
\]</span></p>
</div></div>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>An implication of the hyper-dual approach is that the computational complexity is <span class="math display">\[
\mathcal{O}(m \times \text{cost}(V(\mathbf{s}))),
\]</span> which is <em>independent</em> of the number of state variables.</p>
</div>
</section>
<section id="julia-implementation" class="slide level2 compact-slide">
<h2>Julia Implementation</h2>
<p>It is straightforward to implement the hyper-dual approach to Itô’s lemma in Julia.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="hyper_dual_ito_example" data-code-line-numbers="1-12|1-4|6-8|11-12|1-12"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="hyper_dual_ito_example-1"><a href="#hyper_dual_ito_example-1"></a><span class="im">using</span> <span class="bu">ForwardDiff</span>, <span class="bu">LinearAlgebra</span></span>
<span id="hyper_dual_ito_example-2"><a href="#hyper_dual_ito_example-2"></a><span class="fu">V</span>(s) <span class="op">=</span> <span class="fu">sum</span>(s<span class="op">.^</span><span class="fl">2</span>) <span class="co"># example function</span></span>
<span id="hyper_dual_ito_example-3"><a href="#hyper_dual_ito_example-3"></a>n, m  <span class="op">=</span> <span class="fl">100</span>, <span class="fl">1</span> <span class="co"># number of state variables and shocks</span></span>
<span id="hyper_dual_ito_example-4"><a href="#hyper_dual_ito_example-4"></a>s0, f, g <span class="op">=</span> <span class="fu">ones</span>(n), <span class="fu">ones</span>(n), <span class="fu">ones</span>(n,m) <span class="co"># example values</span></span>
<span id="hyper_dual_ito_example-5"><a href="#hyper_dual_ito_example-5"></a></span>
<span id="hyper_dual_ito_example-6"><a href="#hyper_dual_ito_example-6"></a><span class="co"># Analytical drift</span></span>
<span id="hyper_dual_ito_example-7"><a href="#hyper_dual_ito_example-7"></a>∇f, H <span class="op">=</span> <span class="fl">2</span><span class="op">*</span>s0, <span class="fu">Matrix</span>(<span class="fl">2.0</span><span class="op">*</span>I, n,n) <span class="co"># gradient and Hessian</span></span>
<span id="hyper_dual_ito_example-8"><a href="#hyper_dual_ito_example-8"></a>drift_analytical <span class="op">=</span> ∇f<span class="op">'*</span>f <span class="op">+</span> <span class="fl">0.5</span><span class="fu">*tr</span>(g<span class="op">'*</span>H<span class="op">*</span>g) <span class="co"># analytical drift</span></span>
<span id="hyper_dual_ito_example-9"><a href="#hyper_dual_ito_example-9"></a></span>
<span id="hyper_dual_ito_example-10"><a href="#hyper_dual_ito_example-10"></a><span class="co"># Hyper-dual approach</span></span>
<span id="hyper_dual_ito_example-11"><a href="#hyper_dual_ito_example-11"></a><span class="fu">F</span>(ϵ) <span class="op">=</span> <span class="fu">sum</span>([<span class="fu">V</span>(s0 <span class="op">+</span> g[<span class="op">:</span>,i]<span class="op">*</span>ϵ<span class="op">/</span><span class="fu">sqrt</span>(<span class="fl">2</span>) <span class="op">+</span> f<span class="op">/</span>(<span class="fl">2</span>m)<span class="op">*</span>ϵ<span class="op">^</span><span class="fl">2</span>) for i <span class="op">=</span> <span class="fl">1</span><span class="op">:</span>m])</span>
<span id="hyper_dual_ito_example-12"><a href="#hyper_dual_ito_example-12"></a>drift_hyperdual <span class="op">=</span> ForwardDiff.<span class="fu">derivative</span>(ϵ <span class="op">-&gt;</span> ForwardDiff.<span class="fu">derivative</span>(F, ϵ), <span class="fl">0.0</span>) <span class="co"># scalar 2nd derivative</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="fragment">
<p>To verify correctness, we can compare the analytical and hyper-dual drifts:</p>
<div id="4" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><a></a><span class="co"># Compare</span></span>
<span id="cb1-2"><a></a>drift_analytical, drift_hyperdual</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>(300.0, 300.0)</code></pre>
</div>
</div>
</div>
</section>
<section id="computational-cost" class="slide level2 compact-slide">
<h2>Computational Cost</h2>
<p>This figure shows how the cost of computing the drift of a function <span class="math inline">\(V\)</span> scales with the number of state variables and Brownian shocks.</p>
<ul>
<li>The cost is independent of the number of state variables.</li>
<li>It increases <em>linearly</em> — instead of exponentially — with the number of Brownian shocks.</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="Figures/itos_lemma1.png" style="width:100.0%"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="Figures/itos_lemma2.png" style="width:100.0%"></p>
</div></div>
<div style="font-size: 0.75em; margin-top: 0.5em; text-align: left;">
<p><em>Notes:</em> Cost is measured as the execution time of <span class="math inline">\(\frac{\mathbb{E}dV}{dt}(\mathbf{s})\)</span> relative to that of <span class="math inline">\(V(\mathbf{s})\)</span>. The left panel fixes <span class="math inline">\(m=1\)</span> and varies <span class="math inline">\(n\)</span> from 1 to 100; the right panel fixes <span class="math inline">\(n=100\)</span> and varies <span class="math inline">\(m\)</span> from 1 to 100. In this example, <span class="math inline">\(V\)</span> is a two-layer neural network, and execution times are averaged over 10,000 runs on a mini-batch of 512 states.</p>
</div>
</section>
<section id="computational-cost-continued" class="slide level2 compact-slide">
<h2>Computational Cost (continued)</h2>
<p>We benchmark the performance of the hyper-dual approach to Itô’s lemma by comparing the execution time of alternative methods.</p>
<ul>
<li>In addition to finite differences and naive autodiff, we also consider the analytical expression for the derivatives</li>
</ul>
<p>The <span class="text-orange"><strong>hyper-dual Itô’s lemma</strong></span> method is faster and less memory-intensive than using the analytical expression for the derivatives.</p>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: right;">FLOPs</th>
<th style="text-align: right;">Memory</th>
<th style="text-align: right;">Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1. Finite differences</td>
<td style="text-align: right;">9,190,800</td>
<td style="text-align: right;">112,442,048</td>
<td style="text-align: right;">1.58%</td>
</tr>
<tr class="even">
<td style="text-align: left;">2. Naive autodiff</td>
<td style="text-align: right;">2,100,501</td>
<td style="text-align: right;">25,673,640</td>
<td style="text-align: right;">0.00%</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3. Analytical</td>
<td style="text-align: right;">20,501</td>
<td style="text-align: right;">44,428</td>
<td style="text-align: right;">0.00%</td>
</tr>
<tr class="even">
<td style="text-align: left;">4. Hyper-dual Itô</td>
<td style="text-align: right;">599</td>
<td style="text-align: right;">6,044</td>
<td style="text-align: right;">0.00%</td>
</tr>
</tbody>
</table>
</section></section>
<section>
<section id="iii.-the-deep-policy-iteration-algorithm" class="title-slide slide level1 compact-slide center">
<h1>III. The Deep Policy Iteration Algorithm</h1>

</section>
<section id="overcoming-the-curse-of-representation" class="slide level2 compact-slide">
<h2>Overcoming the Curse of Representation</h2>
<p>Our objective is to compute the value function <span class="math inline">\(V(\mathbf{s})\)</span> and policy function <span class="math inline">\(\mathbf{c}(\mathbf{s})\)</span> satisfying the coupled functional equations: <span class="math display">\[
0 = \operatorname{HJB}(\mathbf{s}, \mathbf{c}(\mathbf{s}), V(\mathbf{s})), \qquad \mathbf{c}(\mathbf{s}) = \arg \max_{\mathbf{c}\in\Gamma(\mathbf{s})} \operatorname{HJB}(\mathbf{s},\mathbf{c},V(\mathbf{s})),
\]</span> where <span class="math display">\[
\operatorname{HJB}(\mathbf{s},\mathbf{c},V) = u(\mathbf{c}) - \rho V + \nabla_{\mathbf{s}} V(\mathbf{s}) \cdot \mathbf{f}(\mathbf{s},\mathbf{c}) + \tfrac{1}{2} \operatorname{Tr}(\mathbf{g}(\mathbf{s},\mathbf{c}) \mathbf{H}_{\mathbf{s}} V(\mathbf{s}) \mathbf{g}(\mathbf{s},\mathbf{c})),
\]</span> and <span class="math inline">\(\mathbf{f}(\mathbf{s},\mathbf{c})\)</span> is the drift of <span class="math inline">\(\mathbf{s}\)</span> and <span class="math inline">\(\mathbf{g}(\mathbf{s},\mathbf{c})\)</span> is the diffusion matrix.</p>
<div class="fragment">
<div style="border-top: 1px solid #ccc; margin: 1.5em 0;">

</div>
<p>To solve for <span class="math inline">\(V(\mathbf{s})\)</span> and <span class="math inline">\(\mathbf{c}(\mathbf{s})\)</span> numerically, we must represent them on a computer.</p>
<ul>
<li><p>A traditional approach is to discretize the state space and interpolate between grid points.</p></li>
<li><p>In Module 4, we showed that such grid-based approximations can be viewed as shallow neural networks with fixed breakpoints.</p></li>
</ul>
<p><span class="text-orange"><strong>Neural networks</strong></span> generalize this idea</p>
<ul>
<li>It allows us to learn flexible breakpoints and nonlinear combinations of basis functions.</li>
<li>A DNN can approximate complex value and policy functions with relatively few parameters.</li>
</ul>
</div>
</section>
<section id="overcoming-the-curse-of-optimization" class="slide level2 compact-slide">
<h2>Overcoming the Curse of Optimization</h2>
<p>We now turn to the challenge of training the DNNs to satisfy the functional equations above.</p>
<ul>
<li>A key difficulty lies in performing the maximization step efficiently, without resorting to costly root-finding procedures.</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.0em;">

</div>
<p>Our approach builds on <span class="text-blue"><strong>generalized policy iteration</strong></span> (see, e.g., <span class="citation" data-cites="SuttonBarto2018">Sutton and Barto (<a href="#/references" role="doc-biblioref" onclick="">2018</a>)</span>)</p>
<ul>
<li><p>Combining with deep function approximation, alternating between policy evaluation and policy improvement.</p></li>
<li><p>This leads to the <span class="text-orange"><strong>Deep Policy Iteration (DPI)</strong></span> algorithm.</p></li>
</ul>
<div style="margin-top: 1.0em;">

</div>
<p>The algorithm proceeds in three stages:</p>
<ol type="1">
<li>Sampling</li>
<li>Policy improvement</li>
<li>Policy evaluation</li>
</ol>
<div style="margin-top: 1.0em;">

</div>
</div>
<div class="fragment">
<div title="Simplifying assumptions.">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Simplifying assumptions.</strong></p>
</div>
<div class="callout-content">
<p>For clarity, we make several simplifying assumptions that can be relaxed in practice.</p>
<ol type="1">
<li>We adopt plain stochastic gradient descent (SGD) for parameter updates.</li>
<li>We perform exactly one iteration of policy evaluation and policy improvement at each update.</li>
<li>We use a quadratic loss function for the policy evaluation step.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="step-1-sampling" class="slide level2 compact-slide">
<h2>Step 1: Sampling</h2>
<p>We begin by sampling a mini-batch of states <span class="math inline">\(\{\mathbf{s}_i\}_{i=1}^I\)</span> from the state space.</p>
<ul>
<li>This can be done using a uniform distribution within plausible state-space bounds.</li>
<li>Alternatively, we can use an estimated ergodic distribution based on previous iterations.</li>
</ul>
</section>
<section id="step-2-policy-improvement" class="slide level2 compact-slide">
<h2>Step 2: Policy Improvement</h2>
<p>The <em>policy improvement</em> step involves solving the maximization step for each state in the mini-batch.</p>
<ul>
<li>This step can be computationally demanding and lies at the heart of the <em>curse of optimization</em>.</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<div title="Generalized policy iteration.">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Generalized policy iteration.</strong></p>
</div>
<div class="callout-content">
<p>In Module 3, we introduced the policy function iteration, which alternates between <em>policy evaluation</em> and <em>policy improvement</em> steps.</p>
<ul>
<li>In the policy evaluation step, we solve for the new value function <span class="math inline">\(V_{n+1}(\mathbf{s})\)</span> given the policy <span class="math inline">\(\mathbf{c}_n(\mathbf{s})\)</span>.</li>
<li>In the policy improvement step, we solve for the new policy <span class="math inline">\(\mathbf{c}_{n+1}(\mathbf{s})\)</span> given the current value function <span class="math inline">\(V_{n+1}(\mathbf{s})\)</span>.</li>
</ul>
<p>However, when the initial guess for <span class="math inline">\(V\)</span> is far from optimal, fully solving the maximization problem at each iteration is inefficient.</p>
<ul>
<li>This motivates an <em>approximate policy improvement</em> step that performs only a single gradient-based update in the direction of improvement.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>Fix the current parameter vectors for the value and policy functions, <span class="math inline">\(\mathbf{\theta}_V^{j-1}\)</span> and <span class="math inline">\(\mathbf{\theta}_C^{j-1}\)</span>.</p>
<ul>
<li>Evaluate the value and policy functions at the mini-batch of states: <span class="math inline">\(V_{j-1,i} = V(\mathbf{s}_i; \mathbf{\theta}_V^{j-1})\)</span> and <span class="math inline">\(\mathbf{c}_{j-1,i} = \mathbf{c}(\mathbf{s}_i; \mathbf{\theta}_C^{j-1})\)</span>.</li>
<li>We can use the <span class="math inline">\(\{\mathbf{s}_i, V_{j-1,i},\mathbf{c}_{j-1,i}\}_{i=1}^I\)</span> as a training data to update the policy function.</li>
</ul>
</div>
</section>
<section id="step-2-policy-improvement-continued" class="slide level2 compact-slide">
<h2>Step 2: Policy Improvement (continued)</h2>
<p>Our goal is to choose the policy function to maximize (or minimize minus) the value of the HJB operator</p>
<ul>
<li>We can then define the loss function as follows: <span class="math display">\[
\mathcal{L}_p(\mathbf{\theta}_C) = - \frac{1}{2I}\sum_{i=1}^I \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_{C}^{j-1}, \mathbf{\theta}_{V}^{j-1}),
\]</span> where <span class="math inline">\(\operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_{C}^{j-1}, \mathbf{\theta}_{V}^{j-1}) \equiv \operatorname{HJB}(\mathbf{s}_i, \mathbf{c}_{j-1,i}, V_{j-1,i})\)</span>.</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>We perform <em>one step</em> of gradient descent on the loss function to update the policy function parameters:</p>
<div title="Policy improvement step.">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Policy improvement step.</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\begin{equation}\label{eq:policy_improvement_step}
    \mathbf{\theta}_C^{j}
    = \mathbf{\theta}_C^{j-1}
    + \eta_C \frac{1}{I}\sum_{i=1}^I
      \nabla_{\mathbf{\theta}_C} \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j-1}, \mathbf{\theta}_V^{j-1}),
  \end{equation}\]</span></p>
</div>
</div>
</div>
</div>
<p>where <span class="math inline">\(\eta_C\)</span> is the learning rate controlling the step size in parameter space.</p>
</div>
</section>
<section id="step-3-policy-evaluation-i" class="slide level2 compact-slide">
<h2>Step 3: Policy Evaluation I</h2>
<p>We now update the value function given the new policy parameters, <span class="math inline">\(\mathbf{\theta}_C^{j}\)</span>.</p>
<ul>
<li>We present two alternative update rules, each with distinct trade-offs.</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.0em;">

</div>
<p>The first rule mirrors the <span class="text-orange"><strong>explicit method</strong></span> for finite-differences in Module 3.</p>
<ul>
<li>Consider a <em>false-transient</em> formulation that iterates the value function backward in (pseudo-)time:</li>
</ul>
<p><span class="math display">\[
\frac{V(\mathbf{s}; \mathbf{\theta}_V^{j}) - V(\mathbf{s}_i; \mathbf{\theta}_V^{j-1})}{\Delta t} = \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V^{j-1}) \qquad \Rightarrow \qquad V(\mathbf{s}; \mathbf{\theta}_V^{j}) = \underbrace{V(\mathbf{s}_i; \mathbf{\theta}_V^{j-1}) + \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V^{j-1}) \Delta t}_{\text{target value } \hat{V}_i^{j-1}},
\]</span> where the HJB is evaluated at the new policy parameters, <span class="math inline">\(\mathbf{\theta}_C^{j}\)</span>, but <em>old</em> value function parameters, <span class="math inline">\(\mathbf{\theta}_V^{j-1}\)</span>.</p>
<div style="margin-top: 1.0em;">

</div>
<p>This turns the problem into a supervised learning task given the training data <span class="math inline">\(\{\mathbf{s}_i, \hat{V}_i^{j-1}\}_{i=1}^I\)</span>.</p>
</div>
</section>
<section id="step-3-policy-evaluation-i-continued" class="slide level2 compact-slide">
<h2>Step 3: Policy Evaluation I (continued)</h2>
<p>Define the loss function as the mean-squared error between the target value and the value function: <span class="math display">\[
\mathcal{L}(\mathbf{\theta}_V) = \frac{1}{2I}\sum_{i=1}^I (V(\mathbf{s}_i; \mathbf{\theta}_V) - \hat{V}_i^{j-1})^2,
\]</span></p>
<div class="fragment">
<div style="margin-top: 1.0em;">

</div>
<p>Evaluating the gradient at <span class="math inline">\(\mathbf{\theta}_V^{j-1}\)</span> yields <span class="math display">\[
\nabla_{\mathbf{\theta}_V} \mathcal{L}(\mathbf{\theta}_V^{j-1}) = -\frac{\Delta t}{I}\sum_{i=1}^I \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V^{j-1}) \nabla_{\mathbf{\theta}_V} V(\mathbf{s}_i; \mathbf{\theta}_V),
\]</span></p>
</div>
<div class="fragment">
<div style="margin-top: 1.0em;">

</div>
<p>Taking one step of gradient descent, the corresponding update rule is:</p>
<div title="Policy evaluation step.">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Policy evaluation step.</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[
    \mathbf{\theta}_V^{j}
    = \mathbf{\theta}_V^{j-1}
    + \eta_V \frac{\Delta t}{I}\sum_{i=1}^I \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V^{j-1}) \nabla_{\mathbf{\theta}_V} V(\mathbf{s}_i; \mathbf{\theta}_V^{j-1}),
  \]</span></p>
</div>
</div>
</div>
</div>
<p>where <span class="math inline">\(\eta_V\)</span> is the learning rate.</p>
</div>
</section>
<section id="step-3-policy-evaluation-ii" class="slide level2 compact-slide">
<h2>Step 3: Policy Evaluation II</h2>
<p>The second rule mirrors the <span class="text-orange"><strong>implicit method</strong></span> for finite-differences in Module 3: <span class="math display">\[
\frac{V(\mathbf{s}; \mathbf{\theta}_V^{j}) - V(\mathbf{s}_i; \mathbf{\theta}_V^{j-1})}{\Delta t} = \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V^{j}),
\]</span> As in the implicit finite-difference method, we can take the limit as <span class="math inline">\(\Delta t \to \infty\)</span>.</p>
<div class="fragment">
<div style="border-top: 1px solid #ccc; margin: 0.75em 0;">

</div>
<div class="columns">
<div class="column" style="width:50%;">
<p>In this case, the loss function becomes MSE of HJB residuals: <span class="math display">\[
\mathcal{L}(\mathbf{\theta}_V) = \frac{1}{2I}\sum_{i=1}^I \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V)^2,
\]</span></p>
</div><div class="column" style="width:50%;">
<p>The gradient is given by <span class="math display">\[
\nabla_{\mathbf{\theta}_V} \mathcal{L}(\mathbf{\theta}_V) = \frac{1}{I}\sum_{i=1}^I \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V) \nabla_{\mathbf{\theta}_V} \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V),
\]</span></p>
</div></div>
<div style="border-top: 1px solid #ccc; margin: 0.75em 0;">

</div>
</div>
<div class="fragment">
<p>Evaluating at <span class="math inline">\(\mathbf{\theta}_V^{j-1}\)</span> yields</p>
<div title="Policy evaluation step 2.">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Policy evaluation step 2.</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[
    \mathbf{\theta}_V^{j}
    = \mathbf{\theta}_V^{j-1}
    - \eta_V \frac{1}{I}\sum_{i=1}^I \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V^{j-1}) \nabla_{\mathbf{\theta}_V} \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V^{j-1}),
  \]</span></p>
</div>
</div>
</div>
</div>
<p>where <span class="math inline">\(\eta_V\)</span> is the learning rate.</p>
</div>
</section>
<section id="the-deep-policy-iteration-algorithm" class="slide level2 compact-slide">
<h2>The Deep Policy Iteration Algorithm</h2>
<p>We can now summarize the complete algorithm:</p>
<div style="background-color: #f5f5f5; padding: 1em; border-left: 4px solid #0072b2; margin: 1em 0; font-size: 0.85em;">
<p><strong>Algorithm: Deep Policy Iteration (DPI)</strong></p>
<p><strong>Input:</strong> Initial parameters <span class="math inline">\(\mathbf{\theta}_V^{0}\)</span> and <span class="math inline">\(\mathbf{\theta}_C^{0}\)</span></p>
<p><strong>Output:</strong> Value function <span class="math inline">\(V(\mathbf{s}; \mathbf{\theta}_V)\)</span>, policy function <span class="math inline">\(\mathbf{c}(\mathbf{s}; \mathbf{\theta}_C)\)</span></p>
<p><strong>Initialize:</strong> <span class="math inline">\(j \gets 0\)</span></p>
<p><strong>Repeat</strong> for <span class="math inline">\(j = 1, 2, \ldots\)</span>:</p>
<ol type="1">
<li><p><strong>Sampling:</strong><br>
Sample a mini-batch of states <span class="math inline">\(\{\mathbf{s}_i\}_{i=1}^I\)</span>.</p></li>
<li><p><strong>Policy improvement (actor update):</strong><br>
Update <span class="math inline">\(\mathbf{\theta}_C\)</span> with one step of gradient descent on the loss function.</p></li>
<li><p><strong>Policy evaluation (critic update):</strong><br>
Update <span class="math inline">\(\mathbf{\theta}_V\)</span> using the explicit or implicit policy evaluation step.</p></li>
</ol>
</div>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<div title="The trade-off between the two update rules.">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>The trade-off between the two update rules.</strong></p>
</div>
<div class="callout-content">
<p>Minimizing the Bellman residual directly is known to be more stable but it is often slower than iterative policy evaluation.</p>
<ul>
<li>Moreover, the implicit policy evaluation step requires relatively costly third-order derivatives, since <span class="math inline">\(\nabla_{\mathbf{\theta}_V} \operatorname{HJB}(\mathbf{s}_i, \mathbf{\theta}_C^{j}, \mathbf{\theta}_V)\)</span> involves the Hessian of <span class="math inline">\(V\)</span>.</li>
<li>As a rule of thumb, it is preferable to start with the explicit policy evaluation step for speed, and switch to the implicit policy evaluation step if necessary.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="iv.-applications-asset-pricing" class="title-slide slide level1 compact-slide center">
<h1>IV. Applications: Asset Pricing</h1>

</section>
<section id="asset-pricing-the-two-trees-model" class="slide level2 compact-slide">
<h2>Asset Pricing: The Two-Trees Model</h2>
<p>Next, we apply the DPI algorithm to solve a variety of economic and financial problems.</p>
<ul>
<li>We focus on three canonical domains of finance: asset pricing, corporate finance, and portfolio choice.</li>
<li>We illustrate how the DPI algorithm can be applied to solve a variety of economic and financial problems.</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>To start, we consider the familiar <span class="text-orange"><strong>two-trees model</strong></span> from Module 3.</p>
<div style="border-top: 1px solid #ccc; margin: 0.75em 0;">

</div>
<div class="columns">
<div class="column" style="width:50%;">
<p>The pricing condition for a log investor implies <span class="math display">\[
v_t = \mathbb{E}_t \left[ \int_{0}^{\infty} e^{-\rho s} s_{t+s}\,ds \right],
\]</span> where the relative share process <span class="math inline">\(s_t\)</span> evolves as <span class="math display">\[
d s_t = - 2 \sigma^2 s_t(1-s_t)\!\left(s_t - \tfrac12\right) dt
          + \sigma s_t(1-s_t)(dB_{1,t} - dB_{2,t}).
\]</span></p>
</div><div class="column" style="width:50%;">
<p>The price-consumption ratio <span class="math inline">\(v_t\)</span> satisfies the HJB equation: <span class="math display">\[
\rho v = s - v_s \, 2\sigma^2 s(1-s)\!\left(s-\tfrac12\right)
          + \frac{1}{2} v_{ss}\,\big(2\sigma^2 s^2(1-s)^2\big),
\]</span> with boundary conditions <span class="math inline">\(v(0) = 0\)</span> and <span class="math inline">\(v(1) = 1/\rho\)</span>.</p>
</div></div>
<div style="border-top: 1px solid #ccc; margin: 0.75em 0;">

</div>
<div style="margin-top: 1.5em;">

</div>
<p>It is straightforward to solve this one-dimensional problem using finite differences or collocation methods</p>
<ul>
<li>But we solve it here using the DPI framework to illustrate the workflow.</li>
</ul>
</div>
</section>
<section id="julia-implementation-1" class="slide level2 compact-slide">
<h2>Julia Implementation</h2>
<p>We now implement the two-trees model in Julia, starting with the <em>model struct</em>.</p>
<div id="cell-two_trees_struct" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a></a><span class="pp">@kwdef</span> <span class="kw">struct</span> TwoTrees</span>
<span id="cb3-2"><a></a>    ρ<span class="op">::</span><span class="dt">Float64 </span><span class="op">=</span> <span class="fl">0.04</span></span>
<span id="cb3-3"><a></a>    σ<span class="op">::</span><span class="dt">Float64 </span><span class="op">=</span> <span class="fu">sqrt</span>(<span class="fl">0.04</span>)</span>
<span id="cb3-4"><a></a>    μ<span class="op">::</span><span class="dt">Float64 </span><span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb3-5"><a></a>    μₛ<span class="op">::</span><span class="dt">Function </span><span class="op">=</span> s <span class="op">-&gt;</span> @. <span class="op">-</span><span class="fl">2</span> <span class="op">*</span> σ<span class="op">^</span><span class="fl">2</span> <span class="op">*</span> s <span class="op">*</span> (<span class="fl">1</span><span class="op">-</span>s) <span class="op">*</span> (s<span class="op">-</span><span class="fl">0.5</span>)   <span class="co"># drift of s</span></span>
<span id="cb3-6"><a></a>    σₛ<span class="op">::</span><span class="dt">Function </span><span class="op">=</span> s <span class="op">-&gt;</span> @. <span class="fu">sqrt</span>(<span class="fl">2</span>) <span class="op">*</span> σ <span class="op">*</span> s <span class="op">*</span> (<span class="fl">1</span><span class="op">-</span>s)          <span class="co"># diffusion of s</span></span>
<span id="cb3-7"><a></a><span class="kw">end</span>;</span>
<span id="cb3-8"><a></a></span>
<span id="cb3-9"><a></a>m <span class="op">=</span> <span class="fu">TwoTrees</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div id="two_trees_struct" class="cell-output cell-output-display" data-execution_count="1">
<pre><code>TwoTrees(0.04, 0.2, 0.02, var"#6#10"{Float64}(0.2), var"#7#11"{Float64}(0.2))</code></pre>
</div>
</div>
<div class="fragment">
<div style="margin-top: 0.5em;">

</div>
<p>We next implement the <span class="text-orange"><strong>hyper-dual</strong></span> approach to Ito’s lemma to compute the drift and diffusion of the state variable <span class="math inline">\(s\)</span>.</p>
<div id="hyper_dual_ito" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><a></a><span class="im">using</span> <span class="bu">ForwardDiff</span></span>
<span id="cb5-2"><a></a><span class="kw">function</span> <span class="fu">drift_hyper</span>(V<span class="op">::</span><span class="dt">Function</span>, s<span class="op">::</span><span class="dt">AbstractMatrix</span>, m<span class="op">::</span><span class="dt">TwoTrees</span>)</span>
<span id="cb5-3"><a></a>    <span class="fu">F</span>(ϵ) <span class="op">=</span> <span class="fu">V</span>(s <span class="op">+</span> m.<span class="fu">σₛ</span>(s)<span class="op">/</span><span class="fu">sqrt</span>(<span class="fl">2</span>)<span class="op">*</span>ϵ <span class="op">+</span> m.<span class="fu">μₛ</span>(s)<span class="op">/</span><span class="fl">2</span><span class="op">*</span>ϵ<span class="op">^</span><span class="fl">2</span>)</span>
<span id="cb5-4"><a></a>    <span class="cf">return</span> ForwardDiff.<span class="fu">derivative</span>(ϵ <span class="op">-&gt;</span> ForwardDiff.<span class="fu">derivative</span>(F, ϵ), <span class="fl">0.0</span>)</span>
<span id="cb5-5"><a></a><span class="kw">end</span>;</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
<div class="fragment">
<div style="margin-top: 0.5em;">

</div>
<p>To validate the implementation, we can compare the analytical and hyper-dual drifts:</p>
<div id="cell-hyper_dual_ito_validation" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><a></a><span class="im">using</span> <span class="bu">Random</span></span>
<span id="cb6-2"><a></a>rng <span class="op">=</span> <span class="fu">Xoshiro</span>(<span class="fl">0</span>)  </span>
<span id="cb6-3"><a></a>s   <span class="op">=</span> <span class="fu">rand</span>(rng, <span class="fl">1</span>, <span class="fl">1000</span>)</span>
<span id="cb6-4"><a></a><span class="co"># Exact drift for test function</span></span>
<span id="cb6-5"><a></a><span class="fu">V_test</span>(s) <span class="op">=</span> <span class="fu">sum</span>(s<span class="op">.^</span><span class="fl">2</span>, dims <span class="op">=</span> <span class="fl">1</span>)</span>
<span id="cb6-6"><a></a>drifts_exact <span class="op">=</span> <span class="fu">map</span>(<span class="fl">1</span><span class="op">:</span><span class="fu">size</span>(s, <span class="fl">2</span>)) <span class="cf">do</span> i</span>
<span id="cb6-7"><a></a>    ∇V, H <span class="op">=</span> <span class="fl">2</span> <span class="op">*</span> s[<span class="op">:</span>,i], <span class="fl">2</span> <span class="op">*</span> <span class="fu">Matrix</span>(I,<span class="fu">length</span>(s[<span class="op">:</span>,i]),<span class="fu">length</span>(s[<span class="op">:</span>,i]))</span>
<span id="cb6-8"><a></a>    ∇V<span class="op">'</span> <span class="op">*</span> m.<span class="fu">μₛ</span>(s[<span class="op">:</span>,i]) <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="fu">tr</span>(m.<span class="fu">σₛ</span>(s[<span class="op">:</span>,i])<span class="ch">' * H * m.σₛ(s[:,i]))</span></span>
<span id="cb6-9"><a></a><span class="cf">end</span><span class="ch">'</span></span>
<span id="cb6-10"><a></a>drifts_hyper <span class="op">=</span> <span class="fu">drift_hyper</span>(V_test, s, m)</span>
<span id="cb6-11"><a></a>errors <span class="op">=</span> <span class="fu">maximum</span>(<span class="fu">abs</span>.(drifts_exact <span class="op">-</span> drifts_hyper))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div id="hyper_dual_ito_validation" class="cell-output cell-output-display" data-execution_count="1">
<pre><code>1.734723475976807e-18</code></pre>
</div>
</div>
</div>
</section>
<section id="neural-network-implementation" class="slide level2 compact-slide">
<h2>Neural Network Implementation</h2>
<p>We now implement the neural network representation of the value function.</p>
<div id="cell-two_trees_nn" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb8-1"><a></a><span class="im">using</span> <span class="bu">Lux</span></span>
<span id="cb8-2"><a></a>model <span class="op">=</span> <span class="fu">Chain</span>(</span>
<span id="cb8-3"><a></a>    <span class="fu">Dense</span>(<span class="fl">1</span> <span class="op">=&gt;</span> <span class="fl">25</span>, Lux.gelu),</span>
<span id="cb8-4"><a></a>    <span class="fu">Dense</span>(<span class="fl">25</span> <span class="op">=&gt;</span> <span class="fl">25</span>, Lux.gelu),</span>
<span id="cb8-5"><a></a>    <span class="fu">Dense</span>(<span class="fl">20</span> <span class="op">=&gt;</span> <span class="fl">1</span>)</span>
<span id="cb8-6"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div id="two_trees_nn" class="cell-output cell-output-display" data-execution_count="1">
<div class="ansi-escaped-output">
<pre>Chain(
    layer_1 = Dense(1 =&gt; 25, gelu_tanh),          <span class="ansi-bright-black-fg"># 50 parameters</span>
    layer_2 = Dense(25 =&gt; 25, gelu_tanh),         <span class="ansi-bright-black-fg"># 650 parameters</span>
    layer_3 = Dense(20 =&gt; 1),                     <span class="ansi-bright-black-fg"># 21 parameters</span>
) <span class="ansi-bright-black-fg">        # Total: </span>721 parameters,
<span class="ansi-bright-black-fg">          #        plus </span>0 states.</pre>
</div>
</div>
</div>
<div class="fragment">
<div style="margin-top: 0.5em;">

</div>
<p>We initialize the parameters and optimizer state using the Adam optimizer with a learning rate of <span class="math inline">\(10^{-3}\)</span>.</p>
<div id="14" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb9-1"><a></a><span class="im">using</span> <span class="bu">Optimisers</span></span>
<span id="cb9-2"><a></a>rng <span class="op">=</span> <span class="fu">Xoshiro</span>(<span class="fl">0</span>)</span>
<span id="cb9-3"><a></a>ps, ls <span class="op">=</span> Lux.<span class="fu">setup</span>(rng, model) <span class="op">|&gt;</span> f64</span>
<span id="cb9-4"><a></a>opt <span class="op">=</span> <span class="fu">Adam</span>(<span class="fl">1e-3</span>)</span>
<span id="cb9-5"><a></a>os <span class="op">=</span> Optimisers.<span class="fu">setup</span>(opt, ps)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div class="ansi-escaped-output">
<pre>(layer_1 = (weight = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0; 0.0; … ; 0.0; 0.0;;], [0.0; 0.0; … ; 0.0; 0.0;;], (0.9, 0.999))<span class="ansi-green-fg">)</span>, bias = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>), layer_2 = (weight = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>, bias = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>), layer_3 = (weight = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>, bias = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0], [0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>))</pre>
</div>
</div>
</div>
</div>
<div class="fragment">
<div style="margin-top: 0.5em;">

</div>
<p>We define the loss function as the mean-squared error between the value function and the target value.</p>
<div id="two_trees_nn_loss" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb10-1"><a></a><span class="fu">loss_fn</span>(ps, ls, s, target) <span class="op">=</span> <span class="fu">mean</span>(abs2, <span class="fu">model</span>(s, ps, ls)[<span class="fl">1</span>] <span class="op">-</span> target)</span>
<span id="cb10-2"><a></a></span>
<span id="cb10-3"><a></a><span class="co"># Target value function</span></span>
<span id="cb10-4"><a></a><span class="kw">function</span> <span class="fu">target</span>(v, s, m; Δt <span class="op">=</span> <span class="fl">0.2</span>)</span>
<span id="cb10-5"><a></a>    hjb <span class="op">=</span> s <span class="op">+</span> <span class="fu">drift_hyper</span>(v, s, m) <span class="op">-</span> m.ρ <span class="op">*</span> <span class="fu">v</span>(s)</span>
<span id="cb10-6"><a></a>    <span class="cf">return</span> <span class="fu">v</span>(s) <span class="op">+</span> hjb <span class="op">*</span> Δt</span>
<span id="cb10-7"><a></a><span class="kw">end</span>;</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="training-the-neural-network" class="slide level2 compact-slide">
<h2>Training the Neural Network</h2>
<p>We now train the neural network using the Adam optimizer.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="two_trees_nn_train" data-code-line-numbers="1-10|1-2|4|5-6|7|8-9|1-10"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="two_trees_nn_train-1"><a href="#two_trees_nn_train-1"></a><span class="co"># Training loop</span></span>
<span id="two_trees_nn_train-2"><a href="#two_trees_nn_train-2"></a>loss_history <span class="op">=</span> <span class="dt">Float64</span>[]</span>
<span id="two_trees_nn_train-3"><a href="#two_trees_nn_train-3"></a><span class="cf">for</span> i <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">40_000</span></span>
<span id="two_trees_nn_train-4"><a href="#two_trees_nn_train-4"></a>    s_batch <span class="op">=</span> <span class="fu">rand</span>(rng, <span class="fl">1</span>,  <span class="fl">128</span>)</span>
<span id="two_trees_nn_train-5"><a href="#two_trees_nn_train-5"></a>    tgt     <span class="op">=</span> <span class="fu">target</span>(s<span class="op">-&gt;</span> <span class="fu">model</span>(s, ps, ls)[<span class="fl">1</span>], s_batch, m, Δt <span class="op">=</span> <span class="fl">1.0</span>)</span>
<span id="two_trees_nn_train-6"><a href="#two_trees_nn_train-6"></a>    loss    <span class="op">=</span> <span class="fu">loss_fn</span>(ps, ls, s_batch, tgt)</span>
<span id="two_trees_nn_train-7"><a href="#two_trees_nn_train-7"></a>    grad    <span class="op">=</span> <span class="fu">gradient</span>(p <span class="op">-&gt;</span> <span class="fu">loss_fn</span>(p, ls, s_batch, tgt), ps)[<span class="fl">1</span>]</span>
<span id="two_trees_nn_train-8"><a href="#two_trees_nn_train-8"></a>    os, ps  <span class="op">=</span> Optimisers.<span class="fu">update</span>(os,ps, grad)</span>
<span id="two_trees_nn_train-9"><a href="#two_trees_nn_train-9"></a>    <span class="fu">push!</span>(loss_history, loss)</span>
<span id="two_trees_nn_train-10"><a href="#two_trees_nn_train-10"></a><span class="cf">end</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="fragment">
<div style="margin-top: 0.5em;">

</div>
<div class="columns">
<div class="column" style="width:48%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/training_history.png" style="width:97.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Training loss over iterations.</span></p>
</div>
</div>
</div><div class="column" style="width:4%;">

</div><div class="column" style="width:48%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/prediction.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">DPI prediction vs.&nbsp;analytical solution.</span></p>
</div>
</div>
</div></div>
</div>
</section>
<section id="the-lucas-orchard-model" class="slide level2 compact-slide">
<h2>The Lucas Orchard Model</h2>
<p>We now extend the two-trees model to a multi-tree economy, known as the <span class="text-orange"><strong>Lucas orchard model</strong></span> (see, e.g., <span class="citation" data-cites="Martin2013LucasOrchard">Martin (<a href="#/references" role="doc-biblioref" onclick="">2013</a>)</span>).</p>
<ul>
<li>By varying the number of trees, we can examine how the DPI algorithm scales with the dimensionality of the state space.</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>Consider a representative investor with log utility who can invest in a riskless asset and <span class="math inline">\(N\)</span> risky assets.</p>
<ul>
<li>Each risky asset <span class="math inline">\(i\)</span> pays a continuous dividend stream <span class="math inline">\(D_{i,t}\)</span> that follows a geometric Brownian motion: <span class="math display">\[
\frac{d D_{i,t}}{D_{i,t}} = \mu_i\,dt + \sigma_i\,dB_{i,t},
\]</span> where each <span class="math inline">\(B_{i,t}\)</span> is a Brownian motion satisfying <span class="math inline">\(dB_{i,t}\,dB_{j,t} = 0\)</span> for <span class="math inline">\(i \neq j\)</span>.</li>
</ul>
</div>
<div class="fragment">
<div title="The HJB equation.">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>The HJB equation.</strong></p>
</div>
<div class="callout-content">
<p>Define the vector of state variables <span class="math inline">\(\mathbf{s}_t = (s_{1,t}, \ldots, s_{N,t})^{\!\top}\)</span>, where <span class="math inline">\(s_{i,t} \equiv D_{i,t}/C_t\)</span> and <span class="math inline">\(C_t = \sum_{i=1}^N D_{i,t}\)</span>.</p>
<ul>
<li>Let <span class="math inline">\(v_{i,t} \equiv P_{i,t}/C_t\)</span> denote the price–consumption ratio of asset <span class="math inline">\(i\)</span>.</li>
<li>The pricing condition for a log investor implies <span class="math display">\[
\rho\,v_i(\mathbf{s})
= s_i
  + \nabla_{\mathbf{s}} v_i(\mathbf{s})^{\!\top} \mathbf{\mu}_s(\mathbf{s})
  + \frac{1}{2}\operatorname{Tr}\!\left[
      \mathbf{\sigma}_s(\mathbf{s})^{\!\top}
      \mathbf{H}_{\mathbf{s}} v_i(\mathbf{s})
      \mathbf{\sigma}_s(\mathbf{s})
    \right]
\]</span> subject to the boundary conditions <span class="math inline">\(v_i(0) = 0\)</span> and <span class="math inline">\(v_i(1) = 1/\rho\)</span>.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="julia-implementation-2" class="slide level2 compact-slide">
<h2>Julia Implementation</h2>
<p>We now implement the Lucas orchard model in Julia.</p>
<ul>
<li>The workflow of the DPI algorithm for the Lucas orchard model is virtually identical to that for the simple two-trees model.</li>
</ul>
<p>As usual, we start by defining the <em>model struct</em>.</p>
<div id="orchard_struct" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb11-1"><a></a><span class="pp">@kwdef</span> <span class="kw">struct</span> LucasOrchard</span>
<span id="cb11-2"><a></a>    ρ<span class="op">::</span><span class="dt">Float64 </span><span class="op">=</span> <span class="fl">0.04</span></span>
<span id="cb11-3"><a></a>    N<span class="op">::</span><span class="dt">Int </span><span class="op">=</span> <span class="fl">10</span></span>
<span id="cb11-4"><a></a>    σ<span class="op">::</span><span class="dt">Vector{Float64} </span><span class="op">=</span> <span class="fu">sqrt</span>(<span class="fl">0.04</span>) <span class="op">*</span> <span class="fu">ones</span>(N)</span>
<span id="cb11-5"><a></a>    μ<span class="op">::</span><span class="dt">Vector{Float64} </span><span class="op">=</span> <span class="fl">0.02</span> <span class="op">*</span> <span class="fu">ones</span>(N)</span>
<span id="cb11-6"><a></a>    μc<span class="op">::</span><span class="dt">Function </span><span class="op">=</span> s <span class="op">-&gt;</span> μ<span class="ch">' * s</span></span>
<span id="cb11-7"><a></a>    σc<span class="op">::</span><span class="dt">Function </span><span class="op">=</span> s <span class="op">-&gt;</span> [s[i,<span class="op">:</span>]<span class="ch">' * σ[i] for i in 1:N]</span></span>
<span id="cb11-8"><a></a>    μₛ<span class="op">::</span><span class="dt">Function </span><span class="op">=</span> s <span class="op">-&gt;</span>  s <span class="op">.*</span> (μ <span class="op">.-</span> <span class="fu">μc</span>(s)<span class="op">-</span> s<span class="op">.*</span>σ<span class="op">.^</span><span class="fl">2</span> <span class="op">.+</span> <span class="fu">sum</span>(<span class="fu">σc</span>(s)[i]<span class="op">.^</span><span class="fl">2</span> for i <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span>N))</span>
<span id="cb11-9"><a></a>    σₛ<span class="op">::</span><span class="dt">Function </span><span class="op">=</span> s <span class="op">-&gt;</span> [s <span class="op">.*</span> ([j <span class="op">==</span> i ? σ[i] <span class="op">:</span> <span class="fl">0</span> for j <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span>N] <span class="op">.-</span> <span class="fu">σc</span>(s)[i]) for i <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span>N] </span>
<span id="cb11-10"><a></a><span class="kw">end</span>;</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="fragment">
<div style="margin-top: 0.5em;">

</div>
<div id="cell-orchard_instantiation" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb12-1"><a></a><span class="co"># Instantiate the model</span></span>
<span id="cb12-2"><a></a><span class="im">using</span> <span class="bu">Distributions</span>, <span class="bu">Random</span></span>
<span id="cb12-3"><a></a>m         <span class="op">=</span> <span class="fu">LucasOrchard</span>(N <span class="op">=</span> <span class="fl">10</span>) <span class="co"># number of assets</span></span>
<span id="cb12-4"><a></a>rng, d    <span class="op">=</span> <span class="fu">MersenneTwister</span>(<span class="fl">0</span>), <span class="fu">Dirichlet</span>(<span class="fu">ones</span>(m.N)) <span class="co"># Dirichlet distribution</span></span>
<span id="cb12-5"><a></a>s_samples <span class="op">=</span> <span class="fu">rand</span>(rng, d, <span class="fl">1_000</span>) <span class="co"># N x 1_000 matrix</span></span>
<span id="cb12-6"><a></a>m.<span class="fu">μₛ</span>(s_samples) <span class="co"># N x 1_000 matrix</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div id="orchard_instantiation" class="cell-output cell-output-display" data-execution_count="1">
<pre><code>10×1000 Matrix{Float64}:
  4.24309e-5    0.000237275   0.000815818  …   8.57681e-5   -0.00169363
 -0.000259516   0.000134325   0.000132953      0.000550971   0.000463926
  0.000193812   0.000154873   0.000418759      0.000564647   5.89399e-5
  0.000118302   0.00023403   -0.00379805       2.65856e-5    0.000710309
  0.000187861   0.000109689   0.000126233      0.000119859  -0.00071501
 -2.52101e-6    4.92026e-5    0.000566168  …   0.00054645    0.000122228
  0.000199586   4.887e-6      7.50461e-5       0.000573028   0.000189173
  2.76043e-5   -0.000877846   0.000535931      0.000335935   0.00040788
 -0.000704084  -9.64787e-5    0.000686905     -0.00331773    0.000103212
  0.000196524   5.00425e-5    0.000440236      0.00051449    0.000352971</code></pre>
</div>
</div>
</div>
</section>
<section id="the-hyper-dual-approach-to-itos-lemma" class="slide level2 compact-slide">
<h2>The Hyper-dual Approach to Ito’s Lemma</h2>
<p>We next implement the hyper-dual approach to Ito’s lemma to compute the drift and diffusion of the state variable <span class="math inline">\(s\)</span>.</p>
<div id="hyper_dual_ito_orchard" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb14-1"><a></a><span class="im">using</span> <span class="bu">ForwardDiff</span></span>
<span id="cb14-2"><a></a><span class="kw">function</span> <span class="fu">drift_hyper</span>(V<span class="op">::</span><span class="dt">Function</span>, s<span class="op">::</span><span class="dt">AbstractMatrix</span>, m<span class="op">::</span><span class="dt">LucasOrchard</span>)</span>
<span id="cb14-3"><a></a>    N, σs, μs <span class="op">=</span> m.N, m.<span class="fu">σₛ</span>(s), m.<span class="fu">μₛ</span>(s) <span class="co"># Preallocations</span></span>
<span id="cb14-4"><a></a>    <span class="fu">F</span>(ϵ) <span class="op">=</span> <span class="fu">sum</span>(<span class="fu">V</span>(s <span class="op">.+</span> σs[i] <span class="op">.*</span> (ϵ <span class="op">/</span> <span class="fu">sqrt</span>(<span class="fl">2</span>)) <span class="op">.+</span> μs <span class="op">.*</span> (ϵ<span class="op">^</span><span class="fl">2</span> <span class="op">/</span> (<span class="fl">2</span> <span class="op">*</span> N))) <span class="cf">for</span> i <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span>N)</span>
<span id="cb14-5"><a></a>    <span class="cf">return</span> ForwardDiff.<span class="fu">derivative</span>(ϵ <span class="op">-&gt;</span> ForwardDiff.<span class="fu">derivative</span>(F, ϵ), <span class="fl">0.0</span>)</span>
<span id="cb14-6"><a></a><span class="cf">end</span>;</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div style="margin-top: 0.5em;">

</div>
<p>The implementation is virtually identical to that for the two-trees model.</p>
<ul>
<li>But now we are dealing with the case of multiple state variables and Brownian motions.</li>
</ul>
<div class="fragment">
<div title="The importance of preallocations.">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>The importance of preallocations.</strong></p>
</div>
<div class="callout-content">
<p>Relative to the two-trees model, we now preallocate arrays for the drift and diffusion of the state variable <span class="math inline">\(s\)</span>,</p>
<ul>
<li>Instead of constructing them inside loops over <span class="math inline">\(i = 1, \ldots, N\)</span>.</li>
<li>In higher-dimensional problems, preallocations avoid repeated memory allocation and garbage collection, improving performance.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="neural-network-implementation-1" class="slide level2 compact-slide">
<h2>Neural Network Implementation</h2>
<p>We next implement the neural network representation of the value function.</p>
<ul>
<li>We use essentially the same architecture as in the two-trees model.</li>
<li>But now the input is the <span class="math inline">\(N\)</span>-dimensional vector of state variables <span class="math inline">\(\mathbf{s}_t\)</span>.</li>
</ul>
<div id="cell-orchard_nn" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb15-1"><a></a>model <span class="op">=</span> <span class="fu">Chain</span>(</span>
<span id="cb15-2"><a></a>    <span class="fu">Dense</span>(m.N <span class="op">=&gt;</span> <span class="fl">25</span>, Lux.gelu),</span>
<span id="cb15-3"><a></a>    <span class="fu">Dense</span>(<span class="fl">25</span> <span class="op">=&gt;</span> <span class="fl">25</span>, Lux.gelu),</span>
<span id="cb15-4"><a></a>    <span class="fu">Dense</span>(<span class="fl">25</span> <span class="op">=&gt;</span> <span class="fl">1</span>)</span>
<span id="cb15-5"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div id="orchard_nn" class="cell-output cell-output-display" data-execution_count="1">
<div class="ansi-escaped-output">
<pre>Chain(
    layer_1 = Dense(10 =&gt; 25, gelu_tanh),         <span class="ansi-bright-black-fg"># 275 parameters</span>
    layer_2 = Dense(25 =&gt; 25, gelu_tanh),         <span class="ansi-bright-black-fg"># 650 parameters</span>
    layer_3 = Dense(25 =&gt; 1),                     <span class="ansi-bright-black-fg"># 26 parameters</span>
) <span class="ansi-bright-black-fg">        # Total: </span>951 parameters,
<span class="ansi-bright-black-fg">          #        plus </span>0 states.</pre>
</div>
</div>
</div>
<div style="margin-top: 0.5em;">

</div>
<div class="fragment">
<p>We initialize the parameters and optimizer state using the Adam optimizer with a learning rate of <span class="math inline">\(10^{-3}\)</span>.</p>
<div id="cell-orchard_nn_init" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb16-1"><a></a>ps, ls <span class="op">=</span> Lux.<span class="fu">setup</span>(rng, model) <span class="op">|&gt;</span> f64</span>
<span id="cb16-2"><a></a>opt <span class="op">=</span> <span class="fu">Adam</span>(<span class="fl">1e-3</span>)</span>
<span id="cb16-3"><a></a>os <span class="op">=</span> Optimisers.<span class="fu">setup</span>(opt, ps)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div id="orchard_nn_init" class="cell-output cell-output-display" data-execution_count="1">
<div class="ansi-escaped-output">
<pre>(layer_1 = (weight = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>, bias = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>), layer_2 = (weight = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>, bias = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>), layer_3 = (weight = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>, bias = <span class="ansi-green-fg">Leaf(Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), </span>([0.0], [0.0], (0.9, 0.999))<span class="ansi-green-fg">)</span>))</pre>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>We define the loss function and the target function as before.</p>
<div id="orchard_nn_loss" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb17-1"><a></a><span class="fu">loss_fn</span>(ps, ls, s, target) <span class="op">=</span> <span class="fu">mean</span>(abs2, <span class="fu">model</span>(s, ps, ls)[<span class="fl">1</span>] <span class="op">-</span> target)</span>
<span id="cb17-2"><a></a></span>
<span id="cb17-3"><a></a><span class="co"># Target</span></span>
<span id="cb17-4"><a></a><span class="kw">function</span> <span class="fu">target</span>(v, s, m; Δt <span class="op">=</span> <span class="fl">0.2</span>)</span>
<span id="cb17-5"><a></a>    v̅ <span class="op">=</span> <span class="fu">v</span>(s)</span>
<span id="cb17-6"><a></a>    hjb <span class="op">=</span> s[<span class="fl">1</span>,<span class="op">:</span>]<span class="ch">' + drift_hyper(v, s, m) - m.ρ * v̅</span></span>
<span id="cb17-7"><a></a>    <span class="cf">return</span> v̅ <span class="op">+</span> hjb <span class="op">*</span> Δt, <span class="fu">mean</span>(abs2, hjb)</span>
<span id="cb17-8"><a></a><span class="kw">end</span>;</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="training-the-neural-network-1" class="slide level2 compact-slide">
<h2>Training the Neural Network</h2>
<div class="columns">
<div class="column" style="width:57%;">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="orchard_nn_train" data-code-line-numbers="1-26|1-7|8-9|11-15|16-17|18-20|21-25"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="orchard_nn_train-1"><a href="#orchard_nn_train-1"></a><span class="co"># Training parameters</span></span>
<span id="orchard_nn_train-2"><a href="#orchard_nn_train-2"></a>max_iter, Δt <span class="op">=</span> <span class="fl">40_000</span>, <span class="fl">1.0</span>  </span>
<span id="orchard_nn_train-3"><a href="#orchard_nn_train-3"></a><span class="co"># Sampling interior and boundary states</span></span>
<span id="orchard_nn_train-4"><a href="#orchard_nn_train-4"></a>d_int  <span class="op">=</span> <span class="fu">Dirichlet</span>(<span class="fu">ones</span>(m.N))            <span class="co"># Interior region</span></span>
<span id="orchard_nn_train-5"><a href="#orchard_nn_train-5"></a>d_edge <span class="op">=</span> <span class="fu">Dirichlet</span>(<span class="fl">0.05</span> <span class="op">.*</span> <span class="fu">ones</span>(m.N))  <span class="co"># Boundary region</span></span>
<span id="orchard_nn_train-6"><a href="#orchard_nn_train-6"></a><span class="co"># Loss history and exponential moving average loss</span></span>
<span id="orchard_nn_train-7"><a href="#orchard_nn_train-7"></a>loss_history, loss_ema_history, α_ema <span class="op">=</span> <span class="dt">Float64</span>[], <span class="dt">Float64</span>[], <span class="fl">0.99</span></span>
<span id="orchard_nn_train-8"><a href="#orchard_nn_train-8"></a><span class="co"># Training loop</span></span>
<span id="orchard_nn_train-9"><a href="#orchard_nn_train-9"></a>p <span class="op">=</span> <span class="fu">Progress</span>(max_iter; desc<span class="op">=</span><span class="st">"Training..."</span>, dt<span class="op">=</span><span class="fl">1.0</span>) <span class="co">#progress bar</span></span>
<span id="orchard_nn_train-10"><a href="#orchard_nn_train-10"></a><span class="cf">for</span> i <span class="op">=</span> <span class="fl">1</span><span class="op">:</span>max_iter</span>
<span id="orchard_nn_train-11"><a href="#orchard_nn_train-11"></a>    <span class="cf">if</span> <span class="fu">rand</span>(rng) <span class="op">&lt;</span> <span class="fl">0.50</span></span>
<span id="orchard_nn_train-12"><a href="#orchard_nn_train-12"></a>        s_batch <span class="op">=</span> <span class="fu">rand</span>(rng, d_int, <span class="fl">128</span>)</span>
<span id="orchard_nn_train-13"><a href="#orchard_nn_train-13"></a>    <span class="cf">else</span></span>
<span id="orchard_nn_train-14"><a href="#orchard_nn_train-14"></a>        s_batch <span class="op">=</span> <span class="fu">rand</span>(rng, d_edge, <span class="fl">128</span>)</span>
<span id="orchard_nn_train-15"><a href="#orchard_nn_train-15"></a>    <span class="cf">end</span></span>
<span id="orchard_nn_train-16"><a href="#orchard_nn_train-16"></a>    <span class="fu">v</span>(s)       <span class="op">=</span> <span class="fu">model</span>(s, ps, ls)[<span class="fl">1</span>] <span class="co"># define value function</span></span>
<span id="orchard_nn_train-17"><a href="#orchard_nn_train-17"></a>    tgt, hjb_res <span class="op">=</span> <span class="fu">target</span>(v, s_batch, m, Δt <span class="op">=</span> Δt) <span class="co">#target/residual</span></span>
<span id="orchard_nn_train-18"><a href="#orchard_nn_train-18"></a>    loss, back <span class="op">=</span> Zygote.<span class="fu">pullback</span>(p <span class="op">-&gt;</span> <span class="fu">loss_fn</span>(p,ls,s_batch,tgt), ps)</span>
<span id="orchard_nn_train-19"><a href="#orchard_nn_train-19"></a>    grad       <span class="op">=</span> <span class="fu">first</span>(<span class="fu">back</span>(<span class="fl">1.0</span>)) <span class="co"># gradient</span></span>
<span id="orchard_nn_train-20"><a href="#orchard_nn_train-20"></a>    os, ps     <span class="op">=</span> Optimisers.<span class="fu">update</span>(os,ps, grad) <span class="co"># update parameters</span></span>
<span id="orchard_nn_train-21"><a href="#orchard_nn_train-21"></a>    loss_ema   <span class="op">=</span> i<span class="op">==</span><span class="fl">1</span> ? loss <span class="op">:</span> α_ema<span class="op">*</span>loss_ema <span class="op">+</span> (<span class="fl">1.0</span><span class="op">-</span>α_ema)<span class="op">*</span>loss</span>
<span id="orchard_nn_train-22"><a href="#orchard_nn_train-22"></a>    <span class="fu">push!</span>(loss_history, loss)</span>
<span id="orchard_nn_train-23"><a href="#orchard_nn_train-23"></a>    <span class="fu">push!</span>(loss_ema_history, loss_ema)</span>
<span id="orchard_nn_train-24"><a href="#orchard_nn_train-24"></a>    <span class="fu">next!</span>(p, showvalues <span class="op">=</span> [(<span class="op">:</span>iter, i),(<span class="st">"Loss"</span>, loss), </span>
<span id="orchard_nn_train-25"><a href="#orchard_nn_train-25"></a>        (<span class="st">"Loss EMA"</span>, loss_ema), (<span class="st">"HJB residual"</span>, hjb_res)])</span>
<span id="orchard_nn_train-26"><a href="#orchard_nn_train-26"></a><span class="cf">end</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div><div class="column" style="width:43%;">
<p>We sample from two Dirichlet distributions:</p>
<ul>
<li>Interior region: uniform distribution over the simplex.</li>
<li>Boundary region: highly concentrated near the edges.</li>
</ul>
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/orchard_loss_history.png" style="width:97.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.00em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Training loss.</span></p>
</div>
</div>
</div></div>
</section>
<section id="test-set-evaluation-i" class="slide level2 compact-slide">
<h2>Test set evaluation I</h2>
<p>We next evaluate the model’s performance on <em>out-of-sample</em> test sets.</p>
<div style="margin-top: 0.5em;">

</div>
<div class="columns">
<div class="column" style="width:55%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/orchard_prediction.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Two-trees prediction.</span></p>
</div>
</div>
</div><div class="column" style="width:45%;">
<p>We consider an extremely asymmetric configuration:</p>
<ul>
<li><span class="math inline">\(\mathbf{s} = (s_1, 1 - s_1, 0, \ldots, 0)\)</span>, the two-trees special case.</li>
<li>This configuration lies outside the region used for training.</li>
</ul>
<div style="margin-top: 0.5em;">

</div>
<p>The network’s prediction replicates the analytical solution.</p>
<ul>
<li>Even though was not trained on this configuration,</li>
</ul>
</div></div>
</section>
<section id="test-set-evaluation-ii" class="slide level2 compact-slide">
<h2>Test set evaluation II</h2>
<p>Our second test set draws states from a symmetric Dirichlet distribution with parameters <span class="math inline">\(\boldsymbol{\alpha} = \alpha_{\text{scale}} (1, 1, \ldots, 1)\)</span></p>
<ul>
<li><span class="math inline">\(\alpha_{\text{scale}}\)</span> controls the concentration of points within the simplex.</li>
<li>Samples are concentrated near the center (or edges) of the simplex when <span class="math inline">\(\alpha_{\text{scale}} &gt; 1\)</span> (or <span class="math inline">\(&lt; 1\)</span>).</li>
</ul>
<div class="fragment">
<div class="columns">
<div class="column" style="width:48%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/dirichlet_plotting.png" style="width:97.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Dirichlet densities.</span></p>
</div>
</div>
</div><div class="column" style="width:4%;">

</div><div class="column" style="width:48%;">
<div class="fragment">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/orchard_residuals.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Orchard residuals.</span></p>
</div>
</div>
</div>
</div></div>
</div>
</section>
<section id="comparison-with-other-methods" class="slide level2 compact-slide">
<h2>Comparison with other methods</h2>
<p>We next compare the DPI algorithm with other methods for solving high-dimensional dynamic models.</p>
<ul>
<li>We use the Lucas orchard model as a benchmark.</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>Finite-difference schemes become computationally infeasible beyond a few dimensions</p>
<ul>
<li>Chebyshev collocation on full tensor-product grids also suffers from exponential growth in cost.</li>
</ul>
<div style="margin-top: 1.5em;">

</div>
<p>We then compare the time to solution of the DPI algorithm with the <span class="text-orange"><strong>Smolyak method</strong></span> (<span class="citation" data-cites="smolyak1963quadrature">Smolyak (<a href="#/references" role="doc-biblioref" onclick="">1963</a>)</span>).</p>
<ul>
<li>The Smolyak method is a sparse-grid technique for approximating multivariate functions</li>
<li>It is commonly used for solving high-dimensional dynamic models.</li>
</ul>
</div>
</section>
<section id="time-to-solution" class="slide level2 compact-slide">
<h2>Time to solution</h2>

<img data-src="Figures/timetosolution3.png" style="width:85.0%" class="r-stretch"><div style="font-size: 0.75em; margin-top: 0.5em; text-align: left; color: #666666;">
<p><em>Notes:</em> Figure shows the time-to-solution of the DPI algorithm, measured by the number of minutes required for the MSE or 90th-percentile squared error to fall below <span class="math inline">\(10^{-8}\)</span>. The parameter values are <span class="math inline">\(\rho = 0.04\)</span>, <span class="math inline">\(\gamma = 1\)</span>, <span class="math inline">\(\varrho = 0.0\)</span>, <span class="math inline">\(\mu = 0.015\)</span>, and <span class="math inline">\(\sigma = 0.1\)</span>. The HJB residuals are computed on a random sample of <span class="math inline">\(2^{13}\)</span> points from the state space.</p>
</div>
</section>
<section id="smolyak-vs.-dpi-algorithm" class="slide level2 compact-slide">
<h2>Smolyak vs.&nbsp;DPI algorithm</h2>

<img data-src="Figures/performance_rmse.png" style="width:85.0%" class="r-stretch"><div style="font-size: 0.75em; margin-top: 0.5em; text-align: left; color: #666666;">
<p><em>Notes:</em> Figure compares the time-to-solution of the DPI method and the Smolyak methods of orders 2, 3, and 4. The tolerance is set to <span class="math inline">\(10^{-3}\)</span>, the highest accuracy threshold reached by all Smolyak variants. The parameter values are <span class="math inline">\(\rho = 0.04\)</span>, <span class="math inline">\(\gamma = 1\)</span>, <span class="math inline">\(\varrho = 0.0\)</span>, <span class="math inline">\(\mu = 0.015\)</span>, and <span class="math inline">\(\sigma = 0.1\)</span>. The HJB residuals are computed on a random sample of <span class="math inline">\(2^{13}\)</span> points from the state space.</p>
</div>
</section></section>
<section>
<section id="v.-applications-corporate-finance" class="title-slide slide level1 compact-slide center">
<h1>V. Applications: Corporate Finance</h1>

</section>
<section id="the-hennessy-and-whited-2007-model" class="slide level2 compact-slide">
<h2>The Hennessy and Whited (2007) Model</h2>
<p>We now apply the DPI algorithm to a corporate finance problem, a simplified version of the model in <span class="citation" data-cites="Hennessy2007">Hennessy and Whited (<a href="#/references" role="doc-biblioref" onclick="">2007</a>)</span>.</p>
<ul>
<li>This problem illustrates how the DPI algorithm can handle problems with <span class="text-orange"><strong>kinks</strong></span> and <span class="text-blue"><strong>inaction regions</strong></span>.</li>
</ul>
<div class="fragment">
<div style="border-top: 1px solid #ccc; margin: 0.75em 0;">

</div>
<div class="columns">
<div class="column" style="width:50%;">
<p>Consider a firm with operating profits <span class="math inline">\(\pi(k_t, z_t) = e^{z_t} k_t^\alpha\)</span>.</p>
<ul>
<li><p>Log productivity follows an Ornstein–Uhlenbeck process: <span class="math display">\[
d z_t = -\theta (z_t - \bar{z})\,dt + \sigma\,dB_t,
\]</span> where <span class="math inline">\(\theta, \sigma &gt; 0\)</span>.</p></li>
<li><p>Given investment rate <span class="math inline">\(i_t\)</span> and depreciation rate <span class="math inline">\(\delta\)</span>, capital evolves as <span class="math display">\[
d k_t = (i_t - \delta)\,k_t\,dt.
\]</span></p></li>
</ul>
</div><div class="column" style="width:50%;">
<p>The firm faces linear equity issuance costs <span class="math inline">\(\lambda &gt; 0\)</span>.</p>
<ul>
<li><p>Operating profits net of adjustment costs are <span class="math display">\[
D^*(k_t, z_t, i_t) = e^{z_t} k_t^\alpha - \left(i_t + 0.5 \chi i_t^2 \right) k_t,
\]</span> where <span class="math inline">\(\chi &gt; 0\)</span> is the adjustment cost parameter.</p></li>
<li><p>The firm’s dividend policy is given by <span class="math display">\[
D_t = D_t^* (1 + \lambda \mathbf{1}_{D_t^* &lt; 0}).
\]</span></p></li>
</ul>
</div></div>
<div style="border-top: 1px solid #ccc; margin: 0.75em 0;">

</div>
</div>
<div class="fragment">
<p>The firm chooses the investment rate <span class="math inline">\(i_t\)</span> to maximize the expected discounted value of future dividends: <span class="math display">\[
v(\mathbf{s}_0) =
  \max_{\{i_t\}_{t\ge 0}}
  \mathbb{E}\left[ \int_{0}^{\infty} e^{-\rho s} D(k_s, z_s, i_s)\,ds \right],
\]</span> subject to the law of motion for the state vector <span class="math inline">\(\mathbf{s}_t = (k_t, z_t)^{\!\top}\)</span>.</p>
</div>
</section>
<section id="the-hjb-equation" class="slide level2 compact-slide">
<h2>The HJB Equation</h2>
<p>The HJB equation is given by <span class="math display">\[
  0 = \max_{i}\, \operatorname{HJB}(\mathbf{s}, i, v(\mathbf{s})),
\]</span> where <span class="math display">\[
  \operatorname{HJB}(\mathbf{s}, i, v) =
  D(k, z, i)
  + \nabla v^\top \mathbf{\mu}_{s}(\mathbf{s}, i)
  + \tfrac{1}{2}\,\mathbf{\sigma}_{s}(\mathbf{s}, i)^\top \mathbf{H}_{\mathbf{s}} v\, \mathbf{\sigma}_{s}(\mathbf{s}, i)
  - \rho v.
\]</span></p>
<p>The first-order condition for the optimal investment rate is <span class="math display">\[
  \frac{\partial \operatorname{HJB}}{\partial i}
  = -\big(1 + \lambda\,\mathbf{1}_{D^*(k,z,i)&lt;0}\big)\big[1 + \chi(i-\delta)\big]k
    + v_k(\mathbf{s})k = 0.
\]</span></p>
<div class="fragment">
<div style="border-top: 1px solid #ccc; margin: 0.75em 0;">

</div>
<p>Consider a <em>special case</em> where there investment is fixed at <span class="math inline">\(i = \delta\)</span> and productivity is constant <span class="math inline">\(\theta = \sigma = 0\)</span>.</p>
<ul>
<li>In this case, capital is constant</li>
<li>From the HJB equation, we obtain the value function</li>
</ul>
<p><span class="math display">\[\begin{equation}\label{eq:hw_value_function_special_case}
  v(k, z) = \frac{D(k, z, \delta)}{\rho} =
  \begin{cases}
    \frac{e^{z} k^\alpha - \delta k}{\rho}, &amp; \text{if } k \leq k_{\max}(z), \\[5pt]
    \frac{e^{z} k^\alpha - \delta k}{\rho} (1+\lambda), &amp; \text{if } k &gt; k_{\max}(z),
  \end{cases}
\end{equation}\]</span> where <span class="math inline">\(k_{\max}(z) = \left(\tfrac{e^{z}}{\delta}\right)^{\!\frac{1}{1-\alpha}}\)</span>.</p>
</div>
</section>
<section id="value-function-and-derivatives-for-special-case" class="slide level2 compact-slide">
<h2>Value function and derivatives for special case</h2>
<div class="columns">
<div class="column" style="width:48%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/hw_special_case_v_level.png" style="width:97.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Value function</span></p>
</div>
</div>
</div><div class="column" style="width:4%;">

</div><div class="column" style="width:48%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/hw_special_case_v_derivatives.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Value function derivative</span></p>
</div>
</div>
</div></div>
</section>
<section id="optimal-dividend-policy-and-investment-rate" class="slide level2 compact-slide">
<h2>Optimal Dividend Policy and Investment Rate</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/capitalequity.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Dividends</span></p>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/capitalinvestment.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Investment Rate</span></p>
</div>
</div>
</div></div>
</section>
<section id="global-sensitivity-analysis" class="slide level2 compact-slide">
<h2>Global sensitivity analysis</h2>
<p>This problem has only two state variables, so it can be easily solved using finite differences</p>
<ul>
<li>But we are often interested in the solution for a large number of parameter values</li>
<li>For instance, how does the solution vary with investment or equity issuance costs?</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>In particular, we are interested in knowing which equilibrium moments are more sensitive to parameters</p>
<ul>
<li>This way we know which aspects of the data are more informative about the parameters</li>
<li>To answer these questions, we need to perform a <span class="text-orange"><strong>global sensitivity analysis</strong></span></li>
</ul>
</div>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>Performing such global sensitivity analysis can be computationally very costly</p>
<ul>
<li>Using the DPI method, we can overcome this challenge</li>
<li><span class="text-blue"><strong>Solution:</strong></span> add the vector of parameters to the state space</li>
<li>In deep-reinforcement learning, this is known as <span class="text-green"><strong>universal value functions</strong></span></li>
</ul>
</div>
</section>
<section id="global-sensitivity-analysis-results" class="slide level2 compact-slide">
<h2>Global sensitivity analysis results</h2>

<img data-src="Figures/moments.png" style="width:89.0%" class="r-stretch"></section></section>
<section>
<section id="vi.-applications-portfolio-choice" class="title-slide slide level1 compact-slide center">
<h1>VI. Applications: Portfolio Choice</h1>

</section>
<section id="portfolio-choice-with-realistic-dynamics" class="slide level2 compact-slide">
<h2>Portfolio Choice with Realistic Dynamics</h2>
<p>As our third application, we consider a <span class="text-blue"><strong>portfolio choice</strong></span> problem with realistic dynamics</p>
<ul>
<li>The problem will feature a large number of state variables, shocks, and controls</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>We consider the problem of an investor with Epstein-Zin preferences</p>
<ul>
<li>Investor must choose consumption and portfolio</li>
<li>Investor has access to <span class="math inline">\(5\)</span> risky assets and a risk-free asset</li>
</ul>
</div>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>Volatility is constant and expected returns are affine functions of the state <span class="math inline">\(\mathbf{x}_t \in \mathbb{R}^n\)</span></p>
<ul>
<li>The state variable follows a multivariate Ornstein-Uhlenbeck (O-U) process: <span class="math display">\[
d \mathbf{x}_t = - \Phi \mathbf{x}_t + \sigma_{\mathbf{x}} d \mathbf{B}_t,
\]</span></li>
</ul>
</div>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p>To ensure absence of arbitrage, expected returns are derived from a <span class="text-red"><strong>state-price density</strong></span> (SPD)</p>
<ul>
<li>The price of risk and interest rate are affine functions of the state <span class="math display">\[
r(\mathbf{x}_t) = r_0 + \mathbf{r}_1^{\top} \mathbf{x}_t, \qquad \qquad
\boldsymbol{\eta}(\mathbf{x}_t) = \boldsymbol{\eta}_0 + \boldsymbol{\eta}_1^\top \mathbf{x}_t.
\]</span></li>
</ul>
</div>
</section>
<section id="state-variables" class="slide level2 compact-slide">
<h2>State variables</h2>
<div style="text-align: center; color: #666666; margin-bottom: 1em;">
<p><strong>List of State Variables Driving the Expected Returns of Assets</strong></p>
</div>
<div style="font-size: 0.85em;">
<table style="width: 100%; border-collapse: collapse;">
<thead>
<tr>
<th style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd; width: 15%;">
<strong>Variable</strong>
</th>
<th style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd; width: 45%;">
<strong>Description</strong>
</th>
<th style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd; width: 15%;">
<strong>Mean</strong>
</th>
<th style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd; width: 15%;">
<strong>S.D. (%)</strong>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(\pi_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Inflation
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
0.032
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
2.3
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(y_t^{\$}(1)\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log 1-Year Nominal Yield
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
0.043
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
3.1
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(yspr_t^{\$}\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log 5-Year Minus 1-Year Nominal Yield Spread
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
0.006
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
0.7
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(\Delta z_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Real GDP Growth
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
0.030
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
2.4
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(\Delta d_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Stock Dividend-to-GDP Growth
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
-0.002
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
6.3
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(d_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Stock Dividend-to-GDP Level
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
-0.270
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
30.5
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(pd_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Stock Price-to-Dividend Ratio
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
3.537
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
42.6
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(\Delta\tau_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Tax Revenue-to-GDP Growth
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
0.000
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
5
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(\tau_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Tax Revenue-to-GDP Level
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
-1.739
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
6.5
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(\Delta g_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Spending-to-GDP Growth
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
0.006
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
7.6
</td>
</tr>
<tr>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
<span class="math inline">\(g_t\)</span>
</td>
<td style="text-align: left; padding: 0.4em; border-bottom: 1px solid #ddd;">
Log Spending-to-GDP Level
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
-1.749
</td>
<td style="text-align: right; padding: 0.4em; border-bottom: 1px solid #ddd;">
12.9
</td>
</tr>
</tbody>
</table>
</div>
<div style="font-size: 0.75em; margin-top: 0.5em; text-align: left; color: #666666;">
<p><em>Notes:</em> The table shows the list of 11 state variables driving expected returns in our economy, along with their mean and standard deviation. The data are collected from https://www.publicdebtvaluation.com/data. See <span class="citation" data-cites="jiang2024publicdebt">Jiang et al. (<a href="#/references" role="doc-biblioref" onclick="">2024</a>)</span> for more details.</p>
</div>
</section>
<section id="estimation-of-continuous-time-spd" class="slide level2 compact-slide">
<h2>Estimation of continuous-time SPD</h2>
<p><span class="text-blue"><strong>State dynamics estimation</strong></span></p>
<ul>
<li>We run a discrete time VAR on the <span class="math inline">\(n = 11\)</span> state variables: <span class="math display">\[
\mathbf{x}_t = \Psi \mathbf{x}_{t-1} + \mathbf{u}_t.
\]</span></li>
<li>Find <span class="math inline">\(\Phi\)</span> and <span class="math inline">\(\sigma_{\mathbf{x}}\)</span> such that the time-integrated continuous-time process coincides with VAR</li>
</ul>
<div class="fragment">
<div style="margin-top: 1.5em;">

</div>
<p><span class="text-orange"><strong>State-price density estimation</strong></span></p>
<ul>
<li>Find <span class="math inline">\((r_0,\mathbf{r}_1,\boldsymbol{\eta}_0, \boldsymbol{\eta}_1)\)</span> to minimize squared deviations of model-implied and data moments</li>
<li>Moments: time-integrated time series for nominal yields, real yields, and expected stock returns</li>
</ul>
</div>
</section>
<section id="bond-yields-and-equity-expected-returns" class="slide level2 compact-slide">
<h2>Bond Yields and Equity Expected Returns</h2>

<img data-src="Figures/fitted_yields.png" style="width:65.0%" class="r-stretch"></section>
<section id="time-series-of-expected-returns-and-optimal-allocations" class="slide level2 compact-slide">
<h2>Time Series of Expected Returns and Optimal Allocations</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/ts_expected_returns.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Expected Returns</span></p>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/ts_optimal_allocation.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Asset Allocation</span></p>
</div>
</div>
</div></div>
</section>
<section id="optimal-allocation" class="slide level2 compact-slide">
<h2>Optimal allocation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/policy1.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Consumption-Wealth Ratio</span></p>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/policy3.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Stock</span></p>
</div>
</div>
</div></div>
</section>
<section id="optimal-portfolio-continued" class="slide level2 compact-slide">
<h2>Optimal portfolio (continued)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/policy6.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Nominal Long-Term Bond</span></p>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="display: flex; flex-direction: column;">
<p><img data-src="Figures/policy5.png" style="width:100.0%"></p>
<div style="font-size: 0.85em; margin-top: 0.5em; display: flex; justify-content: center;">
<p><span style="font-weight: bold; color: #666666;">Real Long-Term Bond</span></p>
</div>
</div>
</div></div>
</section>
<section id="conclusion" class="slide level2 compact-slide">
<h2>Conclusion</h2>
<p>In this lecture, we learned methods that alleviate the <span class="text-blue"><em>three curses of dimensionality</em></span></p>
<ol type="1">
<li>Use deep neural networks to represent <span class="math inline">\(V(\mathbf{s})\)</span></li>
<li>Compute expectations using Itô’s lemma and automatic differentiation</li>
<li>Gradient-based update rule that does not rely on root-finding procedures</li>
</ol>
<div style="margin-top: 1.5em;">

</div>
<p>The <span class="text-red"><strong>DPI algorithm</strong></span> allows us to solve high-dimensional problems</p>
<ul>
<li>Method is effective in situations where leading numerical methods fail</li>
</ul>
<div style="margin-top: 1.5em;">

</div>
<p>Ability to solve rich problems can be an invaluable tool in economic analysis</p>
<ul>
<li>We oftentimes make assumptions that have no clear economic interest
<ul>
<li>Assumptions are made only for <span class="text-green">tractability</span> reasons</li>
</ul></li>
<li>Our method enables researchers to focus on economically interesting models
<ul>
<li>Instead of focusing on models that we could easily solve</li>
</ul></li>
</ul>
</section>
<section id="references" class="slide level2 compact-slide smaller scrollable">
<h2>References</h2>
<div class="references">

</div>



<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-DuarteDuarteSilva2024" class="csl-entry" role="listitem">
Duarte, Victor, Diogo Duarte, and Dejanir H. Silva. 2024. <span>“Machine Learning for Continuous-Time Finance.”</span> <em>The Review of Financial Studies</em> 37 (11): 3217–71. <a href="https://doi.org/10.1093/rfs/hhae043">https://doi.org/10.1093/rfs/hhae043</a>.
</div>
<div id="ref-Hennessy2007" class="csl-entry" role="listitem">
Hennessy, Christopher A, and Toni M Whited. 2007. <span>“How Costly Is External Financing? Evidence from a Structural Estimation.”</span> <em>Journal of Finance</em> 62 (4): 1705–45.
</div>
<div id="ref-jiang2024publicdebt" class="csl-entry" role="listitem">
Jiang, Zhengyang, Hanno Lustig, Stijn Van Nieuwerburgh, and Mindy Z. Xiaolan. 2024. <span>“The u.s. Public Debt Valuation Puzzle.”</span> <em>Econometrica</em> 92 (4): 1309–47. <a href="https://doi.org/10.3982/ECTA17674">https://doi.org/10.3982/ECTA17674</a>.
</div>
<div id="ref-Martin2013LucasOrchard" class="csl-entry" role="listitem">
Martin, Ian. 2013. <span>“The Lucas Orchard.”</span> <em>Econometrica</em> 81 (1): 55–111. <a href="https://doi.org/10.3982/ECTA8446">https://doi.org/10.3982/ECTA8446</a>.
</div>
<div id="ref-smolyak1963quadrature" class="csl-entry" role="listitem">
Smolyak, Sergei Abramovich. 1963. <span>“Quadrature and Interpolation Formulas for Tensor Products of Certain Classes of Functions.”</span> In <em>Doklady Akademii Nauk</em>, 148:1042–45. 5. Russian Academy of Sciences.
</div>
<div id="ref-SuttonBarto2018" class="csl-entry" role="listitem">
Sutton, Richard S., and Andrew G. Barto. 2018. <em>Reinforcement Learning: An Introduction</em>. 2nd ed. Cambridge, MA: MIT Press. <a href="http://incompleteideas.net/book/the-book-2nd.html">http://incompleteideas.net/book/the-book-2nd.html</a>.
</div>
</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script>
    function greyOutPreviousFragments(slide) {
      if (!slide || slide.dataset.greyPrevious !== 'true') return;
      
      const fragments = Array
        .from(slide.querySelectorAll('.fragment[data-fragment-index]'))
        .sort(
          (a, b) =>
            (Number(a.dataset.fragmentIndex) || 0) -
            (Number(b.dataset.fragmentIndex) || 0)
        );
      
      if (!fragments.length) return;
      
      fragments.forEach(frag => {
        frag.style.transition = 'opacity 0.8s ease-in-out, color 0.8s ease-in-out';
      });
      
      const visibleFragments = fragments.filter(frag =>
        frag.classList.contains('visible') ||
        frag.classList.contains('current-fragment')
      );
      const maxVisibleIndex = visibleFragments.length
        ? Math.max(
            ...visibleFragments.map(frag => Number(frag.dataset.fragmentIndex) || 0)
          )
        : -1;
      
      fragments.forEach(frag => {
        const fragIndex = Number(frag.dataset.fragmentIndex) || 0;
        if (fragIndex < maxVisibleIndex) {
          frag.style.opacity = '0.4';
          frag.style.color = '#808080';
        } else {
          frag.style.opacity = '1';
          frag.style.color = '';
        }
      });
    }

    Reveal.addEventListener('slidechanged', function(event) {
      setTimeout(() => greyOutPreviousFragments(event.currentSlide), 100);
    });

    Reveal.addEventListener('fragmentshown', function(event) {
      const slide = event.fragment.closest('section');
      setTimeout(() => greyOutPreviousFragments(slide), 50);
    });

    Reveal.addEventListener('fragmenthidden', function(event) {
      const slide = event.fragment.closest('section');
      setTimeout(() => greyOutPreviousFragments(slide), 50);
    });

    // Also check on initial load
    Reveal.addEventListener('ready', function(event) {
      setTimeout(() => {
        document
          .querySelectorAll('section[data-grey-previous="true"]')
          .forEach(slide => greyOutPreviousFragments(slide));
      }, 100);
    });

    // Add line-by-line highlighting to code blocks
    function setupLineByLineHighlighting() {
      const allPre = document.querySelectorAll('pre code');
      allPre.forEach(code => {
        const pre = code.parentElement;
        if (pre && pre.tagName === 'PRE' && !pre.dataset.lineNumbersSetup) {
          let lineNumbers = null;
          
          // Check for vf_iteration function
          if (code.textContent.includes('function vf_iteration')) {
            lineNumbers = '1|2|3|4|5|6|7|8|9|10|11|12|13|14|15';
          }
          // Check for tauchen function
          else if (code.textContent.includes('function tauchen')) {
            lineNumbers = '1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32';
          }
          
          if (lineNumbers) {
            // Set data-line-numbers attribute (Reveal.js should handle this)
            pre.setAttribute('data-line-numbers', lineNumbers);
            
            // Add CSS for line highlighting (fallback if plugin doesn't work)
            if (!document.getElementById('line-highlight-style')) {
              const style = document.createElement('style');
              style.id = 'line-highlight-style';
              style.textContent = `
                pre[data-line-numbers] code {
                  counter-reset: line;
                }
                pre[data-line-numbers] code .hljs-line::before {
                  counter-increment: line;
                  content: counter(line);
                  display: inline-block;
                  width: 2em;
                  padding-right: 1em;
                  color: #999;
                  text-align: right;
                }
                /* Highlight current line based on fragment */
                pre[data-line-numbers] code .hljs-line.fragment.visible {
                  background-color: rgba(255, 255, 0, 0.2);
                }
              `;
              document.head.appendChild(style);
            }
            
            console.log('Set data-line-numbers attribute on code block');
            pre.dataset.lineNumbersSetup = 'true';
          }
        }
      });
    }

    // Try multiple times to catch the code when it's rendered
    function trySetupLineNumbers() {
      setupLineByLineHighlighting();
      setTimeout(setupLineByLineHighlighting, 200);
      setTimeout(setupLineByLineHighlighting, 500);
      setTimeout(setupLineByLineHighlighting, 1000);
      setTimeout(setupLineByLineHighlighting, 2000);
    }

    Reveal.addEventListener('ready', function(event) {
      console.log('Reveal.js ready, setting up line numbers');
      trySetupLineNumbers();
    });

    Reveal.addEventListener('slidechanged', function(event) {
      setTimeout(setupLineByLineHighlighting, 200);
    });

    // Also use MutationObserver to catch when code is added
    const observer = new MutationObserver(function(mutations) {
      setupLineByLineHighlighting();
    });

    observer.observe(document.body, {
      childList: true,
      subtree: true
    });

    // Add footer with link back to homepage
    function addHomepageFooter() {
      // Check if footer already exists
      if (document.getElementById('homepage-footer')) return;
      
      // All slides are in Module subdirectories, so go up one level to reach index.html
      const homePath = '../index.html';
      
      // Create footer element
      const footer = document.createElement('div');
      footer.id = 'homepage-footer';
      footer.innerHTML = '<a href="' + homePath + '" title="Back to homepage">🏠</a>';
      
      // Add to reveal container
      const revealContainer = document.querySelector('.reveal');
      if (revealContainer) {
        revealContainer.appendChild(footer);
      }
    }

    // Add footer when Reveal is ready
    if (typeof Reveal !== 'undefined') {
      Reveal.addEventListener('ready', function(event) {
        addHomepageFooter();
      });
    } else {
      // Fallback: wait for Reveal to be available
      window.addEventListener('load', function() {
        if (typeof Reveal !== 'undefined') {
          Reveal.addEventListener('ready', function(event) {
            addHomepageFooter();
          });
          // Try immediately in case Reveal is already ready
          setTimeout(addHomepageFooter, 100);
        }
      });
    }
    </script>

    <style>
    /* Footer with link back to homepage */
    .reveal #homepage-footer {
      position: fixed;
      bottom: 20px;
      right: 70px;
      z-index: 1000;
      font-size: 0.5em;
      opacity: 0.5;
      transition: opacity 0.3s ease;
    }

    .reveal #homepage-footer:hover {
      opacity: 1;
    }

    .reveal #homepage-footer a {
      color: #0072b2;
      text-decoration: none;
      padding: 3px 5px;
      background-color: rgba(255, 255, 255, 0.9);
      border-radius: 3px;
      box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
      display: inline-block;
      transition: background-color 0.3s ease, transform 0.2s ease;
      line-height: 1;
    }

    .reveal #homepage-footer a:hover {
      background-color: #0072b2;
      transform: scale(1.1);
      text-decoration: none;
    }

    /* Hide footer on title slide if desired */
    .reveal #title-slide ~ #homepage-footer,
    .reveal section#title-slide ~ #homepage-footer {
      display: none;
    }
    </style>

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>